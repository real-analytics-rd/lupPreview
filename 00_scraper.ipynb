{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp scraper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Guardian Scraper\n",
    "\n",
    "> Scraping Premier League Previews from the Guardian."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-size: 200px\">\n",
    "    \n",
    "|            Issues                 |          Solutions          |\n",
    "|------------------------------     |-------------------|\n",
    "|   4 possible formats for previews(old format, new format,Cup's format and a particular format) |Select the appropriate html tags|\n",
    "|   Preview titles are not the same ( we can find Squad Sheets or match preview)|Pick only the names of the teams and eliminate the rest|\n",
    "|   The date of the match is not always available |Pick the preview date|\n",
    "|   The order of the elements and labels are not the same |Using regex patterns to get information|\n",
    "|   Missing values for betting odds |We treat the general case separately and we set up specific regex patterns for these particular cases|\n",
    "|   Odds format is different|We treat the general case separately and we set up specific regex patterns for these particular cases|\n",
    "|   We can find non-numeric values for Odds like (Evens,evens,Eve)|Replace evens by 1-1|\n",
    "|   There are some previews that don't have author and text|For previews that have no text, we put None (not available)|\n",
    "|   The existence of previews for the FA CUP,Carabao Cup,Champions league,World Cup|Filter previews by title,link,topic,aside html section and preview text and allow only Premier League previews|\n",
    "|   We are not sure if the names of the teams are the same as the ones in Opta|Set up a dictionary or check manually to map teams to their IDs|\n",
    "|When we send many requests, the guardian server blocks your IP address, which is interpreted as a DDOS attack|Do a sleep of a random x seconds between requests or change your IP and work with rotating proxy|\n",
    "</div >\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries and Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "import pandas as pd\n",
    "import dateparser\n",
    "import random\n",
    "import requests\n",
    "import logging\n",
    "from guardian_scraper.Db_Config import *\n",
    "from guardian_scraper.parser import *\n",
    "from guardian_scraper.extractor import *\n",
    "from guardian_scraper.mapper import *\n",
    "from guardian_scraper.models.preview import *\n",
    "from typing import Dict, Union\n",
    "from requests_html import HTMLSession\n",
    "from bs4 import BeautifulSoup\n",
    "from time import sleep\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ScrapingTheGuardian Class\n",
    "\n",
    "##### This class represents a scraper from the \"Guardian\" website and has 4 functions:\n",
    "\n",
    "1- <b> calculate_betting_odds </b> returns decimal odds.\n",
    "\n",
    "&emsp;In this section, we will calculate the odds derived from the football preview.\n",
    "<br>&emsp;Considering the following example:\n",
    "<br>&emsp;&emsp; [\"9-20\",\"29-5\",\"6-5\"] \n",
    "<br>&emsp;&emsp;We calculate each sport's rating separately using the following formula:\n",
    "<br>&emsp;&emsp;&emsp; home = (9/20) + 1 \n",
    "<br>&emsp;&emsp;&emsp; away = (29/5) + 1\n",
    "<br>&emsp;&emsp;&emsp; draw = (6/5) + 1\n",
    "<br>&emsp;If we were successful in obtaining decimal odds, they will be returned in a Python dictionary.<br>&emsp;Otherwise, the values will be None (Not available).\n",
    "\n",
    "\n",
    "2- <b> extract_preview_items </b>returns the entire contents of a football preview.\n",
    "\n",
    "&emsp;In this section, we will call the functions defined in the PageExtractor class and return a Python dictionary containing all of this information.\n",
    "<br>&emsp;But first, we use the <b>calculate_betting_odds</b> function to calculate the sports odds for the home team's victory, the away team's victory, and a draw.\n",
    "\n",
    "\"game Id\",\"home team\",\"away team\",\"text\",\"author\",\"venue\",\"referee\",\"odds\",\"odds home team\",\"odds away team\",\"odds draw\", \"preview date\",\"game Date\",\"preview_link\" are the returned values.\n",
    "\n",
    "3- <b> extract_previews </b> returns the information of all extracted previews.\n",
    "\n",
    "&emsp;We retrieve all previews for a given page and go through them one by one, taking the link and getting its data using the \"Guardian Api.\"\n",
    "<br>&emsp;If the \"Guardian Api\" does not work, we will resort to the traditional process of html parsing. \n",
    "<br>&emsp;For each preview in the data extracted from the Guardian, we will look for the id of the home team and the away team and match it with the <b>opta.fixture</b><br>&emsp;database to get the gameID and gameDate and finally we save it in a MongoDb collection.\n",
    "<br>&emsp;If the game exists, we will proceed with the data extraction.\n",
    "The previous function, <b>extract_preview_items</b>, will be called here to extract information from <br>&emsp;each \n",
    "preview, which will then be stored in the list \"all previews.\"\n",
    "<br>&emsp;However, we will only extract previews that do not already exist in the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class ScrapingTheGuardian:\n",
    "    \"\"\"\n",
    "    A class to represent a scraper from the \"Guardian\" website.\n",
    "\n",
    "    ...\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    session : requests_html.HTMLSession\n",
    "        a web session\n",
    "    VENUE_REGEX : str\n",
    "        venue regex expression\n",
    "    REFEREE_REGEX : str\n",
    "        referee regex expression\n",
    "    ODDS_REGEX : str\n",
    "        odds regex expression\n",
    "\n",
    "    Methods\n",
    "    -------\n",
    "    calculate_betting_odds(odds)\n",
    "        returns decimal odds.\n",
    "    extract_preview_items(content,link,preview_date,game_date,game_id,home_team,away_team)\n",
    "        returns all information of a football preview.\n",
    "    extract_previews(self,page,previews_last_date,last_preview,all_previews,df_teams)\n",
    "        returns the information of all extracted previews.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # venue, referee, odds pattern regex\n",
    "    # in some previews, all of the information is on the same line.\n",
    "    VENUE_REGEX = \"Venue(.*)Tickets|Venue(.*),|Venue(.*)\"\n",
    "    REFEREE_REGEX = \"Referee(.*)This season's|Referee(.*)Last season's|Referee(.*)Odds|Referee[\\s](.*)|Ref(.*)Odds\"\n",
    "    # {Odds H 11-8 A 11-8 D 11-8}\n",
    "    # {Odds Liverpool 11-8 Aston Villa 11-8 Draw 11-8}\n",
    "    # missing label {Odds H 11-8 11-8 D 11-8}\n",
    "    # missing value {Odds H 11-8 A 11-8}\n",
    "    ODDS_REGEX = \"Odds[\\s]*[a-zA-Z' ]*(\\d{1,3}-[\\s]*\\d{1,3})[\\s]*[a-zA-Z' ]*(\\d{1,3}-[\\s]*\\d{1,3})([\\s]*[a-zA-Z']*[\\s]*(\\d{1,3}-[\\s]*\\d{1,3}))*\"\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        # Initialize session to start scraping\n",
    "        self.session = HTMLSession()\n",
    "\n",
    "    @staticmethod\n",
    "    def calculate_betting_odds(odds: list) -> Dict[str, object]:\n",
    "        \"\"\"\n",
    "          returns decimal odds.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        odds: list of str\n",
    "            odds values\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        betting_odds: dict of object\n",
    "\n",
    "        \"\"\"\n",
    "        # Initialize betting odds to n/a (not available)\n",
    "        # Some previews may not include odds\n",
    "        odds_home = None\n",
    "        odds_away = None\n",
    "        odds_draw = None\n",
    "\n",
    "        if odds is not None:  # If odds exist\n",
    "            # example of odds:\n",
    "            # {H 4-6 A 43-10 D 3-1}\n",
    "            # {liverpool 4-6 Tottenham 43-10 Draw 3-1}\n",
    "            # {H 4-6 43-10 D 3-1}\n",
    "            # {H 4-6 A 43-10}\n",
    "            # The formula will be (4/6)+1 , (43/10)+1 , (3/1)+1\n",
    "            # Home team odds\n",
    "            betting_odds_home = odds[0]\n",
    "            try:\n",
    "                odds_home = (\n",
    "                    int(betting_odds_home.split(\"-\")[0])\n",
    "                    / int(betting_odds_home.split(\"-\")[1])\n",
    "                ) + 1\n",
    "            except ZeroDivisionError:\n",
    "                logging.error(\"Home team odds are wrong\")\n",
    "                pass\n",
    "            # Away team odds\n",
    "            betting_odds_away = odds[1]\n",
    "            try:\n",
    "                odds_away = (\n",
    "                    int(betting_odds_away.split(\"-\")[0])\n",
    "                    / int(betting_odds_away.split(\"-\")[1])\n",
    "                ) + 1\n",
    "            except ZeroDivisionError:\n",
    "                logging.error(\"Away team odds are wrong\")\n",
    "                pass\n",
    "            # if we have the normal format of odds\n",
    "            # we will have 3 parts(odds_home,odds_away,odds_draw)\n",
    "            if len(odds) >= 3:\n",
    "                odds.pop(2)\n",
    "                # Draw odds\n",
    "                betting_odds_draw = odds[2]\n",
    "                try:\n",
    "                    odds_draw = (\n",
    "                        int(betting_odds_draw.split(\"-\")[0])\n",
    "                        / int(betting_odds_draw.split(\"-\")[1])\n",
    "                    ) + 1\n",
    "                except ZeroDivisionError:\n",
    "                    logging.error(\"Draw odds are wrong\")\n",
    "                    pass\n",
    "\n",
    "        betting_odds = dict(\n",
    "            {\"odds_home\": odds_home, \"odds_away\": odds_away, \"odds_draw\": odds_draw}\n",
    "        )\n",
    "        return betting_odds\n",
    "\n",
    "    @staticmethod\n",
    "    def extract_preview_items(\n",
    "        content: BeautifulSoup,\n",
    "        link: str,\n",
    "        preview_date: datetime,\n",
    "        game_date: datetime,\n",
    "        game_id: int,\n",
    "        home_team: str,\n",
    "        away_team: str,\n",
    "        response_type: str,\n",
    "    ) -> Dict[str, object]:\n",
    "        \"\"\"\n",
    "          returns all information of a football preview\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        content: bs4.BeautifulSoup\n",
    "            the html format of the preview content\n",
    "        link: str\n",
    "            the link of the preview\n",
    "        preview_date: datetime\n",
    "            the preview date\n",
    "        game_date: datetime\n",
    "            the game date\n",
    "        game_id: int\n",
    "            the game id\n",
    "        home_team: str\n",
    "            the home team name\n",
    "        away_team: str\n",
    "            the away team name\n",
    "        response_type: str\n",
    "            the parsing method('api' or 'html')\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        preview_items: dict of object\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        # meth1: extract match infos (venue,referee,odds)\n",
    "        match_infos = PageExtractor.extract_match_infos(\n",
    "            content,\n",
    "            response_type,\n",
    "            ScrapingTheGuardian.VENUE_REGEX,\n",
    "            ScrapingTheGuardian.REFEREE_REGEX,\n",
    "            ScrapingTheGuardian.ODDS_REGEX,\n",
    "        )\n",
    "        venue = match_infos[\"venue\"]\n",
    "        referee = match_infos[\"referee\"]\n",
    "        odds = match_infos[\"odds\"]\n",
    "        # meth2: extract text and author of the preview\n",
    "        text_author = PageExtractor.extract_text_authors(content, response_type)\n",
    "        text = text_author[\"text\"]\n",
    "        author = text_author[\"author\"]\n",
    "        # meth3: calculate betting odds\n",
    "        betting_odds = ScrapingTheGuardian.calculate_betting_odds(odds)\n",
    "        # Home team betting odds\n",
    "        odds_home_team = betting_odds[\"odds_home\"]\n",
    "        # Away team betting odds\n",
    "        odds_away_team = betting_odds[\"odds_away\"]\n",
    "        # Draw betting odds\n",
    "        odds_draw = betting_odds[\"odds_draw\"]\n",
    "        # Return preview items\n",
    "        preview_items = dict(\n",
    "            {\n",
    "                \"game_id\": game_id,\n",
    "                \"home_team\": home_team,\n",
    "                \"away_team\": away_team,\n",
    "                \"text\": text,\n",
    "                \"author\": author,\n",
    "                \"venue\": venue,\n",
    "                \"referee\": referee,\n",
    "                \"odds\": odds,\n",
    "                \"odds_home_team\": odds_home_team,\n",
    "                \"odds_away_team\": odds_away_team,\n",
    "                \"odds_draw\": odds_draw,\n",
    "                \"preview_date\": preview_date,\n",
    "                \"game_date\": game_date,\n",
    "                \"preview_link\": link,\n",
    "            }\n",
    "        )\n",
    "        return preview_items\n",
    "\n",
    "    def extract_previews(\n",
    "        self,\n",
    "        page: BeautifulSoup,\n",
    "        previews_last_date: datetime,\n",
    "        last_preview: bool,\n",
    "        all_previews: list,\n",
    "        df_teams: pd.DataFrame,\n",
    "    ) -> Union[bool, list]:\n",
    "        \"\"\"\n",
    "          save all browsed previews in local\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        page: bs4.BeautifulSoup\n",
    "            the html format of the page\n",
    "        previews_last_date : datetime\n",
    "            the last extracted preview date in the database\n",
    "        last_preview: bool\n",
    "            an indicator to know when we should stop the scraper\n",
    "        all_previews: list\n",
    "            a list that contains all extracted previews\n",
    "        df_teams: pd.DataFrame\n",
    "            a dataframe that contains teams and their different names\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        bool\n",
    "\n",
    "        \"\"\"\n",
    "        # We pick all of the match previews on the webpage.\n",
    "        previews = page.findAll(\"div\", {\"class\": \"fc-item__content\"})\n",
    "        # for each preview we extract its information.\n",
    "        for preview in previews:\n",
    "            # we pick the preview date and we parse it in a date format\n",
    "            preview_date = preview.find(\"time\")[\"datetime\"]\n",
    "            preview_date = dateparser.parse(preview_date, settings={\"TIMEZONE\": \"UTC\"})\n",
    "            # if the date selected from the previews database exists\n",
    "            # and has been reached by the preview date, we stop the loop\n",
    "            # and mark last_preview as True.\n",
    "            if previews_last_date and preview_date.date() <= previews_last_date.date():\n",
    "                logging.info(\"The scraper turned off\")\n",
    "                last_preview = True\n",
    "                break\n",
    "            # Pick the preview link\n",
    "            preview_link = preview.find(\"a\")[\"href\"]\n",
    "\n",
    "            # We extract the last part of the link, which corresponds to the preview api link\n",
    "            api_preview_url = preview_link.replace(\"https://www.theguardian.com\", \"\")\n",
    "            # request the api\n",
    "            response = requests.get(\n",
    "                \"https://content.guardianapis.com/\"\n",
    "                + api_preview_url\n",
    "                + \"?api-key=fd4452e9-76a5-45a1-b30d-bdd156640b9c&show-blocks=all\"\n",
    "            )\n",
    "            # if the api works we get the title and the content of the preview\n",
    "            # else we extract html contents\n",
    "            if response:\n",
    "                logging.info(\"The Guardian Api works\")\n",
    "                # get the preview data\n",
    "                data = response.json()\n",
    "                # preview title\n",
    "                preview_title = data[\"response\"][\"content\"][\"webTitle\"]\n",
    "                # preview content\n",
    "                preview_content = BeautifulSoup(\n",
    "                    data[\"response\"][\"content\"][\"blocks\"][\"body\"][0][\"bodyHtml\"],\n",
    "                    \"html.parser\",\n",
    "                )\n",
    "                # preview date\n",
    "                preview_date = data[\"response\"][\"content\"][\"blocks\"][\"body\"][0][\n",
    "                    \"createdDate\"\n",
    "                ]\n",
    "                preview_date = dateparser.parse(\n",
    "                    preview_date, settings={\"TIMEZONE\": \"UTC\"}\n",
    "                )\n",
    "                response_type = \"api\"\n",
    "\n",
    "            else:\n",
    "                logging.info(\"The Guardian Api does not work\")\n",
    "                preview_content = Parser.parse_page(preview_link, self.session)\n",
    "                preview_title = preview_content.find(\"h1\").text\n",
    "                response_type = \"html\"\n",
    "\n",
    "            # extract team names\n",
    "            names = PageExtractor.extract_teams_names(preview_title)\n",
    "            # Home team and  Away Team\n",
    "            home_team = names[\"home\"]\n",
    "            away_team = names[\"away\"]\n",
    "            # get teams id\n",
    "            home_team_id = PreviewsMapping.get_team_id(home_team, df_teams)\n",
    "            away_team_id = PreviewsMapping.get_team_id(away_team, df_teams)\n",
    "            # pick the preview date\n",
    "            # get the id and the date of the game\n",
    "            game = PreviewsMapping.get_game_id_date(\n",
    "                home_team_id, away_team_id, preview_date\n",
    "            )\n",
    "            # if the game exists we extract the preview information\n",
    "            if game != None:\n",
    "                preview_infos = ScrapingTheGuardian.extract_preview_items(\n",
    "                    preview_content,\n",
    "                    preview_link,\n",
    "                    preview_date,\n",
    "                    game.gameDate,\n",
    "                    game.gameId,\n",
    "                    home_team,\n",
    "                    away_team,\n",
    "                    response_type,\n",
    "                )\n",
    "                logging.info(\"Returned Preview information: {}\".format(preview_infos))\n",
    "                # connect to database\n",
    "                mongoengine_client = MongoClient.connect(\"1\")\n",
    "                # preview class\n",
    "                preview = Previews(\n",
    "                    gameId=preview_infos[\"game_id\"],\n",
    "                    homeTeam=preview_infos[\"home_team\"],\n",
    "                    awayTeam=preview_infos[\"away_team\"],\n",
    "                    text=preview_infos[\"text\"],\n",
    "                    author=preview_infos[\"author\"],\n",
    "                    venue=preview_infos[\"venue\"],\n",
    "                    referee=preview_infos[\"referee\"],\n",
    "                    odds=preview_infos[\"odds\"],\n",
    "                    oddsHomeTeam=preview_infos[\"odds_home_team\"],\n",
    "                    oddsAwayTeam=preview_infos[\"odds_away_team\"],\n",
    "                    oddsDraw=preview_infos[\"odds_draw\"],\n",
    "                    gameDate=preview_infos[\"game_date\"],\n",
    "                    previewDate=preview_infos[\"preview_date\"],\n",
    "                    previewLink=preview_infos[\"preview_link\"],\n",
    "                )\n",
    "                # Validate and save input raw data\n",
    "                MongoClient.save(preview)\n",
    "                all_previews.append(preview_infos)\n",
    "            \n",
    "            else:\n",
    "                logging.info(\"The game does not exist in the Opta database\")\n",
    "                \n",
    "                \n",
    "        return last_preview, all_previews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scraping all pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store scraper actions in a log file\n",
    "logging.basicConfig(\n",
    "    filename=\"scraper.log\", level=logging.INFO, format=\"%(levelname)s:%(message)s\"\n",
    ")\n",
    "# starting url\n",
    "url = \"https://www.theguardian.com/football/series/match-previews?page=36\"\n",
    "# initialize the scraper instance.\n",
    "scraper = ScrapingTheGuardian()\n",
    "# initially we are not at the last page.\n",
    "last_page = False\n",
    "# we'll extract the previews that haven't already been extracted.\n",
    "last_preview = False\n",
    "# we specify the last preview date in the previews collection on which the scraper will be turned off.\n",
    "mongoengine_client = MongoClient.connect(\"1\")\n",
    "previews_last_date = Previews.objects().order_by(\"-previewDate\", \"-gameDate\").first()\n",
    "\n",
    "# if the database is empty we will scrap all pages\n",
    "if previews_last_date != None:\n",
    "    last_previews_date = previews_last_date.previewDate\n",
    "else:\n",
    "    last_previews_date = None\n",
    "    \n",
    "logging.info(\"The last preview date stored in the database is: {}\".format(last_previews_date))\n",
    "all_previews = []\n",
    "# charging teams dictionary\n",
    "df_teams = pd.read_csv(\".//datasets//final_data.csv\")\n",
    "# if we are not at the last page\n",
    "# and we haven't reached an extracted preview\n",
    "# we launch the scraper\n",
    "while not last_page and not last_preview:\n",
    "    # a random timer\n",
    "    time = random.randint(2, 60)\n",
    "    logging.info(\"The scraper will wait {} seconds ...\".format(time))\n",
    "    # wait time seconds\n",
    "    sleep(time)\n",
    "    # get the html format of the page containing previews\n",
    "    page = Parser.parse_page(url, scraper.session)\n",
    "    # launch the scraper , extract previews information\n",
    "    last_preview, all_previews = scraper.extract_previews(\n",
    "        page, last_previews_date, last_preview, all_previews, df_teams\n",
    "    )\n",
    "    # get the url of the following page and verify if we are at the last page\n",
    "    url, last_page = Parser.get_next_page(page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(all_previews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>game_id</th>\n",
       "      <th>home_team</th>\n",
       "      <th>away_team</th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "      <th>venue</th>\n",
       "      <th>referee</th>\n",
       "      <th>odds</th>\n",
       "      <th>odds_home_team</th>\n",
       "      <th>odds_away_team</th>\n",
       "      <th>odds_draw</th>\n",
       "      <th>preview_date</th>\n",
       "      <th>game_date</th>\n",
       "      <th>preview_link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>987970</td>\n",
       "      <td>Tottenham</td>\n",
       "      <td>Everton</td>\n",
       "      <td>Tottenham are euphoric after Wednesday’s Champ...</td>\n",
       "      <td>David Hytner</td>\n",
       "      <td>Tottenham H Stadium</td>\n",
       "      <td>Andre Marriner</td>\n",
       "      <td>[5-4, 5-2, 5-2]</td>\n",
       "      <td>2.250000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>2019-05-10 16:02:57+00:00</td>\n",
       "      <td>2019-05-12 14:00:00</td>\n",
       "      <td>https://www.theguardian.com/football/2019/may/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>987965</td>\n",
       "      <td>Fulham</td>\n",
       "      <td>Newcastle</td>\n",
       "      <td>Scott Parker’s future is no longer in question...</td>\n",
       "      <td>Benjy Nurick</td>\n",
       "      <td>Craven Cottage</td>\n",
       "      <td>Kevin Friend</td>\n",
       "      <td>[6-4, 7-4, 5-2]</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>2.750000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>2019-05-10 15:41:23+00:00</td>\n",
       "      <td>2019-05-12 14:00:00</td>\n",
       "      <td>https://www.theguardian.com/football/2019/may/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>987962</td>\n",
       "      <td>Brighton</td>\n",
       "      <td>Manchester City</td>\n",
       "      <td>Vincent Kompany’s unforgettable winner against...</td>\n",
       "      <td>Benjy Nurick</td>\n",
       "      <td>Amex Stadium</td>\n",
       "      <td>Michael Oliver</td>\n",
       "      <td>[18-1, 2-11, 8-1]</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>1.181818</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>2019-05-10 15:26:50+00:00</td>\n",
       "      <td>2019-05-12 14:00:00</td>\n",
       "      <td>https://www.theguardian.com/football/2019/may/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>987963</td>\n",
       "      <td>Burnley</td>\n",
       "      <td>Arsenal</td>\n",
       "      <td>Arsenal will be glad to see the back of their ...</td>\n",
       "      <td>Graham Searles</td>\n",
       "      <td>Turf Moor</td>\n",
       "      <td>Mike Dean</td>\n",
       "      <td>[23-10, 11-9, 3-1]</td>\n",
       "      <td>3.300000</td>\n",
       "      <td>2.222222</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2019-05-10 15:15:24+00:00</td>\n",
       "      <td>2019-05-12 14:00:00</td>\n",
       "      <td>https://www.theguardian.com/football/2019/may/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>987964</td>\n",
       "      <td>Crystal Palace</td>\n",
       "      <td>Bournemouth</td>\n",
       "      <td>After a season of twists and turns, of giddy h...</td>\n",
       "      <td>Dominic Fifield</td>\n",
       "      <td>Selhurst Park</td>\n",
       "      <td>Roger East</td>\n",
       "      <td>[10-11, 11-4, 3-1]</td>\n",
       "      <td>1.909091</td>\n",
       "      <td>3.750000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2019-05-10 13:52:14+00:00</td>\n",
       "      <td>2019-05-12 14:00:00</td>\n",
       "      <td>https://www.theguardian.com/football/2019/may/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>987636</td>\n",
       "      <td>Manchester City</td>\n",
       "      <td>Fulham</td>\n",
       "      <td>Fulham are the first of the promoted sides to ...</td>\n",
       "      <td>Jamie Jackson</td>\n",
       "      <td>Etihad Stadium</td>\n",
       "      <td>Stuart Atwell</td>\n",
       "      <td>[1-7, 25-1, 10-1]</td>\n",
       "      <td>1.142857</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>2018-09-14 14:00:55+00:00</td>\n",
       "      <td>2018-09-15 14:00:00</td>\n",
       "      <td>https://www.theguardian.com/football/2018/sep/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>987635</td>\n",
       "      <td>Huddersfield Town</td>\n",
       "      <td>Crystal Palace</td>\n",
       "      <td>Both sides go into the game on the back of dis...</td>\n",
       "      <td>Paul Doyle</td>\n",
       "      <td>John Smith’s Stadium</td>\n",
       "      <td>Graham Scott</td>\n",
       "      <td>[23-10, 11-5, 27-17]</td>\n",
       "      <td>3.300000</td>\n",
       "      <td>3.200000</td>\n",
       "      <td>2.588235</td>\n",
       "      <td>2018-09-14 12:35:57+00:00</td>\n",
       "      <td>2018-09-15 14:00:00</td>\n",
       "      <td>https://www.theguardian.com/football/2018/sep/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>987624</td>\n",
       "      <td>Cardiff City</td>\n",
       "      <td>Arsenal</td>\n",
       "      <td>Unai Emery has an excellent chance to record a...</td>\n",
       "      <td>Graham Searles</td>\n",
       "      <td>Cardiff City Stadium</td>\n",
       "      <td>Anthony Taylor</td>\n",
       "      <td>[9-2, 4-7, 3-1]</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>1.571429</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2018-09-01 08:00:48+00:00</td>\n",
       "      <td>2018-09-02 12:30:00</td>\n",
       "      <td>https://www.theguardian.com/football/2018/sep/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>987623</td>\n",
       "      <td>Burnley</td>\n",
       "      <td>Manchester United</td>\n",
       "      <td>Burnley have not made the blistering start the...</td>\n",
       "      <td>Paul Wilson</td>\n",
       "      <td>Turf Moor</td>\n",
       "      <td>Jonathan Moss</td>\n",
       "      <td>[9-2, 4-6, 13-5]</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>3.600000</td>\n",
       "      <td>2018-09-01 08:00:48+00:00</td>\n",
       "      <td>2018-09-02 15:00:00</td>\n",
       "      <td>https://www.theguardian.com/football/2018/sep/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>987630</td>\n",
       "      <td>Watford</td>\n",
       "      <td>Tottenham Hotspur</td>\n",
       "      <td>Something has to give. Watford and Tottenham e...</td>\n",
       "      <td>Graham Searles</td>\n",
       "      <td>Vicarage Road</td>\n",
       "      <td>Andre Marriner</td>\n",
       "      <td>[5-1, 7-10, 3-1]</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.700000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2018-09-01 07:59:48+00:00</td>\n",
       "      <td>2018-09-02 15:00:00</td>\n",
       "      <td>https://www.theguardian.com/football/2018/sep/...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>275 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     game_id          home_team          away_team  \\\n",
       "0     987970          Tottenham            Everton   \n",
       "1     987965             Fulham          Newcastle   \n",
       "2     987962           Brighton    Manchester City   \n",
       "3     987963            Burnley            Arsenal   \n",
       "4     987964     Crystal Palace        Bournemouth   \n",
       "..       ...                ...                ...   \n",
       "270   987636    Manchester City             Fulham   \n",
       "271   987635  Huddersfield Town     Crystal Palace   \n",
       "272   987624       Cardiff City            Arsenal   \n",
       "273   987623            Burnley  Manchester United   \n",
       "274   987630            Watford  Tottenham Hotspur   \n",
       "\n",
       "                                                  text           author  \\\n",
       "0    Tottenham are euphoric after Wednesday’s Champ...     David Hytner   \n",
       "1    Scott Parker’s future is no longer in question...     Benjy Nurick   \n",
       "2    Vincent Kompany’s unforgettable winner against...     Benjy Nurick   \n",
       "3    Arsenal will be glad to see the back of their ...   Graham Searles   \n",
       "4    After a season of twists and turns, of giddy h...  Dominic Fifield   \n",
       "..                                                 ...              ...   \n",
       "270  Fulham are the first of the promoted sides to ...    Jamie Jackson   \n",
       "271  Both sides go into the game on the back of dis...       Paul Doyle   \n",
       "272  Unai Emery has an excellent chance to record a...   Graham Searles   \n",
       "273  Burnley have not made the blistering start the...      Paul Wilson   \n",
       "274  Something has to give. Watford and Tottenham e...   Graham Searles   \n",
       "\n",
       "                    venue         referee                  odds  \\\n",
       "0     Tottenham H Stadium  Andre Marriner       [5-4, 5-2, 5-2]   \n",
       "1          Craven Cottage    Kevin Friend       [6-4, 7-4, 5-2]   \n",
       "2            Amex Stadium  Michael Oliver     [18-1, 2-11, 8-1]   \n",
       "3               Turf Moor       Mike Dean    [23-10, 11-9, 3-1]   \n",
       "4           Selhurst Park      Roger East    [10-11, 11-4, 3-1]   \n",
       "..                    ...             ...                   ...   \n",
       "270        Etihad Stadium   Stuart Atwell     [1-7, 25-1, 10-1]   \n",
       "271  John Smith’s Stadium    Graham Scott  [23-10, 11-5, 27-17]   \n",
       "272  Cardiff City Stadium  Anthony Taylor       [9-2, 4-7, 3-1]   \n",
       "273             Turf Moor   Jonathan Moss      [9-2, 4-6, 13-5]   \n",
       "274         Vicarage Road  Andre Marriner      [5-1, 7-10, 3-1]   \n",
       "\n",
       "     odds_home_team  odds_away_team  odds_draw               preview_date  \\\n",
       "0          2.250000        3.500000   3.500000  2019-05-10 16:02:57+00:00   \n",
       "1          2.500000        2.750000   3.500000  2019-05-10 15:41:23+00:00   \n",
       "2         19.000000        1.181818   9.000000  2019-05-10 15:26:50+00:00   \n",
       "3          3.300000        2.222222   4.000000  2019-05-10 15:15:24+00:00   \n",
       "4          1.909091        3.750000   4.000000  2019-05-10 13:52:14+00:00   \n",
       "..              ...             ...        ...                        ...   \n",
       "270        1.142857       26.000000  11.000000  2018-09-14 14:00:55+00:00   \n",
       "271        3.300000        3.200000   2.588235  2018-09-14 12:35:57+00:00   \n",
       "272        5.500000        1.571429   4.000000  2018-09-01 08:00:48+00:00   \n",
       "273        5.500000        1.666667   3.600000  2018-09-01 08:00:48+00:00   \n",
       "274        6.000000        1.700000   4.000000  2018-09-01 07:59:48+00:00   \n",
       "\n",
       "              game_date                                       preview_link  \n",
       "0   2019-05-12 14:00:00  https://www.theguardian.com/football/2019/may/...  \n",
       "1   2019-05-12 14:00:00  https://www.theguardian.com/football/2019/may/...  \n",
       "2   2019-05-12 14:00:00  https://www.theguardian.com/football/2019/may/...  \n",
       "3   2019-05-12 14:00:00  https://www.theguardian.com/football/2019/may/...  \n",
       "4   2019-05-12 14:00:00  https://www.theguardian.com/football/2019/may/...  \n",
       "..                  ...                                                ...  \n",
       "270 2018-09-15 14:00:00  https://www.theguardian.com/football/2018/sep/...  \n",
       "271 2018-09-15 14:00:00  https://www.theguardian.com/football/2018/sep/...  \n",
       "272 2018-09-02 12:30:00  https://www.theguardian.com/football/2018/sep/...  \n",
       "273 2018-09-02 15:00:00  https://www.theguardian.com/football/2018/sep/...  \n",
       "274 2018-09-02 15:00:00  https://www.theguardian.com/football/2018/sep/...  \n",
       "\n",
       "[275 rows x 14 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(\"~//previews//dataset//previews.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
