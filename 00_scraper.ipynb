{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp scraper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Guardian Scraper\n",
    "\n",
    "> Scraping Premier League Previews from the Guardian."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-size: 200px\">\n",
    "    \n",
    "|            Issues                 |          Solutions          |\n",
    "|------------------------------     |-------------------|\n",
    "|   4 possible formats for previews(old format, new format,Cup's format and a particular format) |Select the appropriate html tags|\n",
    "|   Preview titles are not the same ( we can find Squad Sheets or match preview)|Pick only the names of the teams and eliminate the rest|\n",
    "|   The date of the match is not always available |Pick the preview date|\n",
    "|   The order of the elements and labels are not the same |Using regex patterns to get information|\n",
    "|   Missing values for betting odds |We treat the general case separately and we set up specific regex patterns for these particular cases|\n",
    "|   Odds format is different|We treat the general case separately and we set up specific regex patterns for these particular cases|\n",
    "|   We can find non-numeric values for Odds like (Evens,evens,Eve)|Replace evens by 1-1|\n",
    "|   There are some previews that don't have author and text|For previews that have no text, we put 'n/a' (not available)|\n",
    "|   The existence of previews for the FA CUP,Carabao Cup,Champions league,World Cup|Filter previews by title,link,topic,aside html section and preview text and allow only Premier League previews|\n",
    "|   We are not sure if the names of the teams are the same as the ones in Opta|Set up a dictionary or check manually to map teams to their IDs|\n",
    "|When we send many requests, the guardian server blocks your IP address, which is interpreted as a DDOS attack|Do a sleep of a random x seconds between requests or change your IP and work with rotating proxy|\n",
    "</div >\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries and Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "import re\n",
    "import dateparser\n",
    "import pandas as pd\n",
    "from typing import *\n",
    "from requests_html import HTMLSession\n",
    "from bs4 import BeautifulSoup\n",
    "from time import sleep\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parser Class\n",
    "\n",
    "##### This class is used to parse pages and has two functions:\n",
    "\n",
    "1- <b> parse_page </b> function:retrieves the html format of a given web page link.\n",
    "\n",
    "2- <b> get_next_page </b> function: retrieves the link to the next page and determines if it is the last page of previews in order to stop scraping. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class Parser:\n",
    "    \"\"\"\n",
    "    A class to represent previews pages parser.\n",
    "\n",
    "    ...\n",
    "\n",
    "    Methods\n",
    "    -------\n",
    "    parse_page(page_url,session)\n",
    "        returns the html format of the page.\n",
    "    get_next_page(page)\n",
    "        returns the link of the following page and if it's the last page.\n",
    "    \"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def parse_page(page_url: str, session: HTMLSession) -> BeautifulSoup:\n",
    "        \"\"\"\n",
    "        returns the html format of the page.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        page_url : str\n",
    "            the url of the page\n",
    "        session : requests_html.HTMLSession\n",
    "            the scraper session\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        page : bs4.BeautifulSoup\n",
    "              the html format of the page\n",
    "\n",
    "        \"\"\"\n",
    "        # Request the url\n",
    "        request = session.get(page_url)\n",
    "        # Get the html document of the page\n",
    "        page = BeautifulSoup(request.text, \"html.parser\")\n",
    "        return page\n",
    "\n",
    "    @staticmethod\n",
    "    def get_next_page(page: BeautifulSoup) -> Tuple[str, bool]:\n",
    "        \"\"\"\n",
    "        returns the link of the following page and if it's the last page.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        page : bs4.BeautifulSoup\n",
    "            the html format of the page\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        url: str\n",
    "          the url of the next page\n",
    "        last_page: bool\n",
    "          True if it's the last page, False otherwise.\n",
    "\n",
    "        \"\"\"\n",
    "        # If we are at the last page , last_page = True else last_page = False\n",
    "        last_page = False\n",
    "        # Pick up the pagination HTML part\n",
    "        pagination_section = page.find(\"div\", {\"class\": \"pagination__list\"})\n",
    "        # If we don't find the \"next\" button (it's the last page)\n",
    "        # We are in the last page\n",
    "        if not page.find(\"a\", {\"rel\": \"next\"}):\n",
    "            # We pick up the number of the page and we return the link\n",
    "            html_location = dict({\"aria-label\": \"Current page\"})\n",
    "            page_number = page.find(\"span\", html_location).text\n",
    "            url = (\n",
    "                \"https://www.theguardian.com/football/series/match-previews?page=\"\n",
    "                + page_number\n",
    "            )\n",
    "            last_page = True\n",
    "            return url, last_page\n",
    "        # If it's not the last page, we pick up the link of the following page\n",
    "        else:\n",
    "            url = page.find(\"a\", {\"rel\": \"next\"})[\"href\"]\n",
    "            return url, last_page"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PageExtractor Class\n",
    "\n",
    "##### This class has five functions for extracting data from a given football preview:\n",
    "\n",
    "1- <b> get_values_matching_regex </b> returns values that match a regex expression.\n",
    "\n",
    "&emsp;Because the \"Guardian\" website has two possible formats, we defined two possible classifiers for the p tags <br>&emsp;containing the information to be extracted.<br>\n",
    "&emsp;We go through each p section, and if we find the result, we return it; otherwise, a None is returned.<br>\n",
    "&emsp;The result is a list of tuples, with each tuple representing a value that matches the regex pattern.<br> &emsp;Unsatisfied patterns for regexes that include <b>OR</b> conditions will be empty tuples. That's why you need to get rid of it.\n",
    "\n",
    "2- <b> extract_teams_names </b> returns the names of the two teams in a football preview.\n",
    "\n",
    "&emsp;The preview includes team names at the title level.\n",
    " <br>&emsp;example:\n",
    "          &emsp;&emsp;{{Squad Sheets: Team A v Team B}} \n",
    "         or &emsp;&emsp;{{Team A v Team B: match preview}} \n",
    "         or &emsp;&emsp;{{Team A v Team B: Squad Sheets}}\n",
    "<br>&emsp;As a result, our strategy is to delete the text preceding or following the names and recover each name <br>&emsp;individually.\n",
    "<br>&emsp;If we were successful in obtaining the names, they will be returned in a Python dictionary; <br>&emsp;otherwise, the values will be 'n/a'(Not available).\n",
    "\n",
    "3- <b> extract_text_authors </b>returns the text and author of a football preview.\n",
    "\n",
    "&emsp;It's difficult to determine the position of the text, but it's almost certainly the block with the most <br>&emsp;characters.\n",
    "<br>&emsp;To proceed, we store each paragraph and its size in a Python dictionary, and then we take the <br>&emsp;block with the largest size.\n",
    "<br>&emsp;To be sure, we double-check by only accepting texts with a size greater than 160 because there <br>&emsp;are football previews with no text or author.\n",
    "<br>&emsp;Furthermore, the author information is always under the text section, more specifically in a <br>&emsp;strong tag, so if the text does not exist, the author is missing as well.\n",
    "If we were successful in <br>&emsp;obtaining the text and the author, they will be returned in a Python dictionary. Otherwise, the <br>&emsp;values will be 'n/a'(Not available).\n",
    "\n",
    "4- <b> extract_preview_date </b> returns the date of publication of a football preview.\n",
    "\n",
    "&emsp;We have distinguished two dates for the date of publication: the first is the date of publication, <br>&emsp;and the second is the date of the most recent modification.\n",
    "In this sense, we go through the <br>&emsp;section where the two dates are located and take only the first and use 'dateparser' to convert <br>&emsp;the string into a date in \"yyyy-mm-dd\" format.\n",
    "If we were successful in obtaining the date, it will <br>&emsp; be returned. Otherwise, the value will be 'n/a'(Not available).\n",
    "\n",
    "5- <b> extract_match_infos </b> returns a football match information (venue, referee, odds).\n",
    "\n",
    "&emsp;Here, we'll call the first function <b>get_values_matching_regex</b> , which will allow us to retrieve this<br>&emsp;information by specifying a regex expression for each.<br>&emsp;If this data is not available, the value will be 'n/a'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class PageExtractor:\n",
    "    \"\"\"\n",
    "    A class to represent an information extractor from a football preview.\n",
    "\n",
    "    ...\n",
    "\n",
    "    Methods\n",
    "    -------\n",
    "    get_values_matching_regex(page, regex)\n",
    "        return all matched patterns from a preview page.\n",
    "    extract_teams_names(title)\n",
    "        returns team names from the preview title.\n",
    "    extract_text_authors(page)\n",
    "        returns the text and author of the preview.\n",
    "    extract_preview_date(page)\n",
    "        returns the publication date of the preview.\n",
    "    extract_match_infos(page, venue_regex, referee_regex, odds_regex)\n",
    "        returns a football match information (venue,referee,odds).\n",
    "    \"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def get_values_matching_regex(\n",
    "        page: BeautifulSoup, regex: str\n",
    "    ) -> Union[List[str], None]:\n",
    "        \"\"\"\n",
    "        returns all matched patterns from a preview page.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        page: bs4.BeautifulSoup\n",
    "            the html format of the page\n",
    "        regex: str\n",
    "            the regex expression\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        result: list of str\n",
    "          matched values of the regex expression, None otherwise\n",
    "\n",
    "        \"\"\"\n",
    "        # All Information are located in the \"p tag\" of html\n",
    "        # We pick up all the p tags\n",
    "        # some previews in 2009 have a different html tags and classes\n",
    "        all_p_tags_new_formats = page.find_all(\"p\", {\"class\": \"dcr-bixwrd\"})\n",
    "        all_p_tags_old_format = page.select(\"div > p\")\n",
    "        # if exist\n",
    "        if all_p_tags_new_formats:\n",
    "            paragraphs = all_p_tags_new_formats\n",
    "        else:\n",
    "            paragraphs = all_p_tags_old_format\n",
    "\n",
    "        for paragraph in paragraphs:\n",
    "            # We pick up the string values located in the paragraph\n",
    "            # For \"odds\" information, \"Evens\" or \"Evs\" are replaced by 1-1\n",
    "            pattern_odds = re.compile(\"Evens|Evs\", re.IGNORECASE)\n",
    "            section = pattern_odds.sub(\"1-1\", paragraph.text)\n",
    "            # To extract our information regex pattern\n",
    "            # To ignore case sensitivity we use re.I\n",
    "            pattern_returned_values = re.compile(regex, re.IGNORECASE)\n",
    "            # If a regex match is found, we return the list of values.\n",
    "            # otherwise, an empty array is returned.\n",
    "            if pattern_returned_values.findall(section):\n",
    "                matching_result = pattern_returned_values.findall(section)\n",
    "                # remove empty tuples from the list\n",
    "                # example of a matching_result value\n",
    "                # [('12-5', '11-10', '23-10', '', '')]\n",
    "                result = [element for element in matching_result[0] if element]\n",
    "                return result\n",
    "\n",
    "    @staticmethod\n",
    "    def extract_teams_names(title: str) -> Dict[str, str]:\n",
    "        \"\"\"\n",
    "        returns team names from the preview title.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        title: str\n",
    "            the title of the preview\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        names: dict of str\n",
    "\n",
    "        \"\"\"\n",
    "        # 3 possible formats for previews title\n",
    "        # For example:\n",
    "        # {Squad Sheets: Team A v Team B} or\n",
    "        # {{Team A v Team B : match preview}} or\n",
    "        # {{Team A v Team B : Squad sheets}}\n",
    "        # We remove text before or after team names\n",
    "        pattern = re.compile(\n",
    "            \"Squad Sheets:|: Squad[\\s]sheets|Squad sheets|Squad sheet:|: match preview\",\n",
    "            re.IGNORECASE,\n",
    "        )\n",
    "        preview_title = pattern.sub(\"\", title).strip()\n",
    "        # Names are located in the title of the preview\n",
    "        # Home team\n",
    "        try:\n",
    "            home_team = preview_title.split(\" v \")[0]\n",
    "        except Exception as e:\n",
    "            home_team = \"n/a\"\n",
    "        # Away team\n",
    "        try:\n",
    "            away_team = preview_title.split(\" v \")[1].split(\"\\t\")[\n",
    "                0\n",
    "            ]  # for some preview we find team A v Team B \\t date\n",
    "        except Exception as e:\n",
    "            away_team = \"n/a\"\n",
    "        # we return names\n",
    "        names = dict({\"home\": home_team, \"away\": away_team})\n",
    "        return names\n",
    "\n",
    "    @staticmethod\n",
    "    def extract_text_authors(page: BeautifulSoup) -> Dict[str, str]:\n",
    "        \"\"\"\n",
    "        returns the text and author of the preview.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        page: bs4.BeautifulSoup\n",
    "            the html format of the page\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        preview_text_author: dict of str\n",
    "\n",
    "        \"\"\"\n",
    "        # Preview may not have text and author,\n",
    "        # We initialize author and text to 'n/a' (not available),\n",
    "        author = \"n/a\"\n",
    "        text = \"n/a\"\n",
    "        # all items are stored in a p tag\n",
    "        # Some previews in 2009 have different html tags and classes\n",
    "        all_p_tags_new_formats = page.find_all(\"p\", {\"class\": \"dcr-bixwrd\"})\n",
    "        all_p_tags_old_format = page.select(\"div > p\")\n",
    "        # if exist\n",
    "        if all_p_tags_new_formats:\n",
    "            all_p_tags = all_p_tags_new_formats\n",
    "        else:\n",
    "            all_p_tags = all_p_tags_old_format\n",
    "\n",
    "        # it's quite difficult to determine which section is the text\n",
    "        # the length of the text is usually the longest\n",
    "        # dictionnary to store each p and its length\n",
    "        length_texts = {}\n",
    "        for p in all_p_tags:\n",
    "            section = p.text\n",
    "            length_texts[p] = len(section)\n",
    "\n",
    "        # we pick the section with the largest size\n",
    "        possible_text_section = max(length_texts, key=length_texts.get)\n",
    "        # We double-check and only select texts with a size greater than 160\n",
    "        if len(possible_text_section.text) > 160:\n",
    "            text_section = possible_text_section\n",
    "            text = text_section.text\n",
    "            # the author name is located inside the text section\n",
    "            # it is located in the strong tag\n",
    "            possible_author_section = text_section.find(\"strong\")\n",
    "            # for some previews the author information is not found\n",
    "            # if it's available we take it , else it will be 'n/a'\n",
    "            if str(possible_author_section) != \"None\":\n",
    "                author = possible_author_section.text\n",
    "\n",
    "        preview_text_author = dict({\"text\": text, \"author\": author})\n",
    "        return preview_text_author\n",
    "\n",
    "    @staticmethod\n",
    "    def extract_preview_date(page: BeautifulSoup) -> Union[datetime, str]:\n",
    "        \"\"\"\n",
    "          returns the publication date of the preview.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        page: bs4.BeautifulSoup\n",
    "            the html format of the page\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        preview_date: datetime.date\n",
    "          if not found 'n/a'\n",
    "\n",
    "        \"\"\"\n",
    "        # there are 2 dates for the preview\n",
    "        # the first is the date of publication\n",
    "        # the second is the date of the last modification which is hidden\n",
    "        # we pick only the first one\n",
    "        try:\n",
    "            # Some preview in 2009 have different html tags and classes\n",
    "            html_new_location = dict({\"class\": \"dcr-km9fgb\"})\n",
    "            html_old_location = dict({\"itemprop\": \"datePublished\"})\n",
    "            dates_section_new_format = page.find(\"div\", html_new_location)\n",
    "            dates_section_old_format = page.find(\"time\", html_old_location)\n",
    "            if dates_section_new_format:\n",
    "                dates_section = dates_section_new_format.strings\n",
    "            else:\n",
    "                dates_section = dates_section_old_format.strings\n",
    "\n",
    "            for date in dates_section:\n",
    "                preview_date = dateparser.parse(date).date()\n",
    "                break\n",
    "        except Exception as e:\n",
    "            preview_date = \"n/a\"\n",
    "\n",
    "        return preview_date\n",
    "\n",
    "    @staticmethod\n",
    "    def extract_match_infos(\n",
    "        page: BeautifulSoup, venue_regex: str, referee_regex: str, odds_regex: str\n",
    "    ) -> Dict[str, str]:\n",
    "        \"\"\"\n",
    "          returns a football match information (venue,referee,odds).\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        page: bs4.BeautifulSoup\n",
    "            the html format of the page\n",
    "        venue_regex: str\n",
    "            venue regex expression\n",
    "        referee_regex: str\n",
    "            referee regex expression\n",
    "        odds_regex: str\n",
    "            odds regex expression\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        match_infos: dict of str\n",
    "\n",
    "        \"\"\"\n",
    "        # Extract venue, referee and odds values\n",
    "        try:\n",
    "            venue = PageExtractor.get_values_matching_regex(page, venue_regex)[\n",
    "                0\n",
    "            ].strip()\n",
    "        except Exception as e:\n",
    "            venue = \"n/a\"\n",
    "        try:\n",
    "            referee = PageExtractor.get_values_matching_regex(page, referee_regex)[\n",
    "                0\n",
    "            ].strip()\n",
    "        except Exception as e:\n",
    "            referee = \"n/a\"\n",
    "\n",
    "        odds = PageExtractor.get_values_matching_regex(page, odds_regex)\n",
    "\n",
    "        match_infos = dict({\"venue\": venue, \"referee\": referee, \"odds\": odds})\n",
    "        return match_infos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ScrapingTheGuardian Class\n",
    "\n",
    "##### This class represents a scraper from the \"Guardian\" website and has 3 functions:\n",
    "\n",
    "1- <b> calculate_betting_odds </b> returns decimal odds.\n",
    "\n",
    "&emsp;In this section, we will calculate the odds derived from the football preview.\n",
    "<br>&emsp;Considering the following example:\n",
    "<br>&emsp;&emsp; [\"9-20\",\"29-5\",\"6-5\"] \n",
    "<br>&emsp;&emsp;We calculate each sport's rating separately using the following formula:\n",
    "<br>&emsp;&emsp;&emsp; home = (9/20) + 1 \n",
    "<br>&emsp;&emsp;&emsp; away = (29/5) + 1\n",
    "<br>&emsp;&emsp;&emsp; draw = (6/5) + 1\n",
    "<br>&emsp;If we were successful in obtaining decimal odds, they will be returned in a Python dictionary.<br>&emsp;Otherwise, the values will be 'n/a'(Not available).\n",
    "\n",
    "\n",
    "2- <b> extract_preview_items </b>returns the entire contents of a football preview.\n",
    "\n",
    "&emsp;In this section, we will call the functions defined in the PageExtractor class and return a Python dictionary containing all of this information.\n",
    "<br>&emsp;But first, we use the <b>calculate_betting_odds</b> function to calculate the sports odds for the home team's victory, the away team's victory, and a draw.\n",
    "\n",
    "\"home team\",\"away team\",\"text\",\"author\",\"venue\",\"referee\",\"odds\",\"odds home team\",\"odds away team\",\"odds draw\", \"preview date\" are the values returned.\n",
    "\n",
    "3- <b> extract_previews </b>returns all the information of all browsed previews.\n",
    "\n",
    "&emsp;For a given page, we retrieve all the previews and go through them one by one, taking the link, title, subject, and aside section.\n",
    "<br>&emsp;if the words \"cup\" or \"champions league\" do not belong in these sections, we process the preview\n",
    "<br>&emsp;otherwise, we move on to the next preview.\n",
    "<br>&emsp;The previous function, <b>extract_preview_items</b>, will be called here to extract the information from each preview, which will then be stored in a list called <br>&emsp;<b>all_previews_information</b>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class ScrapingTheGuardian:\n",
    "    \"\"\"\n",
    "    A class to represent a scraper from the \"Guardian\" website.\n",
    "\n",
    "    ...\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    session : requests_html.HTMLSession\n",
    "        a web session\n",
    "    VENUE_REGEX : str\n",
    "        venue regex expression\n",
    "    REFEREE_REGEX : str\n",
    "        referee regex expression\n",
    "    ODDS_REGEX : str\n",
    "        odds regex expression\n",
    "\n",
    "    Methods\n",
    "    -------\n",
    "    calculate_betting_odds(odds)\n",
    "        returns decimal odds.\n",
    "    extract_preview_items(page,title)\n",
    "        returns all information of a football preview\n",
    "    extract_previews(self,page)\n",
    "        returns all the information of all browsed previews\n",
    "    \"\"\"\n",
    "\n",
    "    # venue, referee, odds pattern regex\n",
    "    # in some previews, all of the information is on the same line.\n",
    "    VENUE_REGEX = \"Venue(.*)Tickets|Venue(.*),|Venue(.*)\"\n",
    "    REFEREE_REGEX = \"Referee(.*)This season's|Referee(.*)Last season's|Referee(.*)Odds|Referee(.*)|Ref(.*)Odds\"\n",
    "    # {Odds H 11-8 A 11-8 D 11-8}\n",
    "    # {Odds Liverpool 11-8 Aston Villa 11-8 Draw 11-8}\n",
    "    # missing label {Odds H 11-8 11-8 D 11-8}\n",
    "    # missing value {Odds H 11-8 A 11-8}\n",
    "    ODDS_REGEX = \"Odds[\\s]*.*[\\s]+(\\d{1,3}-\\d{1,3})[\\s]*.*[\\s]+(\\d{1,3}-\\d{1,3})[\\s]*.*[\\s]+(\\d{1,3}-\\d{1,3})|Odds[\\s]*.*[\\s]+(\\d{1,3}-\\d{1,3})[\\s]*.*[\\s]+(\\d{1,3}-\\d{1,3})\"\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        # Initialize session to start scraping\n",
    "        self.session = HTMLSession()\n",
    "\n",
    "    @staticmethod\n",
    "    def calculate_betting_odds(odds: list) -> Dict[str, float]:\n",
    "        \"\"\"\n",
    "          returns decimal odds.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        odds: list of str\n",
    "            odds values\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        betting_odds: dict of float\n",
    "\n",
    "        \"\"\"\n",
    "        # Initialize betting odds to n/a (not available)\n",
    "        # Some previews may not include odds\n",
    "        odds_home = \"n/a\"\n",
    "        odds_away = \"n/a\"\n",
    "        odds_draw = \"n/a\"\n",
    "\n",
    "        if odds is not None:  # If odds exist\n",
    "            # example of odds:\n",
    "            # {H 4-6 A 43-10 D 3-1}\n",
    "            # {liverpool 4-6 Tottenham 43-10 Draw 3-1}\n",
    "            # {H 4-6 43-10 D 3-1}\n",
    "            # {H 4-6 A 43-10}\n",
    "            # The formula will be (4/6)+1 , (43/10)+1 , (3/1)+1\n",
    "            # Home team odds\n",
    "            betting_odds_home = odds[0]\n",
    "            try:\n",
    "                odds_home = (\n",
    "                    int(betting_odds_home.split(\"-\")[0])\n",
    "                    / int(betting_odds_home.split(\"-\")[1])\n",
    "                ) + 1\n",
    "            except ZeroDivisionError:\n",
    "                pass\n",
    "            # Away team odds\n",
    "            betting_odds_away = odds[1]\n",
    "            try:\n",
    "                odds_away = (\n",
    "                    int(betting_odds_away.split(\"-\")[0])\n",
    "                    / int(betting_odds_away.split(\"-\")[1])\n",
    "                ) + 1\n",
    "            except ZeroDivisionError:\n",
    "                pass\n",
    "            # if we have the normal format of odds\n",
    "            # we will have 3 parts(odds_home,odds_away,odds_draw)\n",
    "            if len(odds) == 3:\n",
    "                # Draw odds\n",
    "                betting_odds_draw = odds[2]\n",
    "                try:\n",
    "                    odds_draw = (\n",
    "                        int(betting_odds_draw.split(\"-\")[0])\n",
    "                        / int(betting_odds_draw.split(\"-\")[1])\n",
    "                    ) + 1\n",
    "                except ZeroDivisionError:\n",
    "                    pass\n",
    "\n",
    "        betting_odds = dict(\n",
    "            {\"odds_home\": odds_home, \"odds_away\": odds_away, \"odds_draw\": odds_draw}\n",
    "        )\n",
    "        return betting_odds\n",
    "\n",
    "    @staticmethod\n",
    "    def extract_preview_items(page: BeautifulSoup, title: str) -> Dict[str, object]:\n",
    "        \"\"\"\n",
    "          returns all information of a football preview\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        page: bs4.BeautifulSoup\n",
    "            the html format of the page\n",
    "        title: str\n",
    "            the title of the preview\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        preview_items: dict of object\n",
    "\n",
    "        \"\"\"\n",
    "        # meth1: extract team names\n",
    "        names = PageExtractor.extract_teams_names(title)\n",
    "        # Home team and  Away Team\n",
    "        home_team = names[\"home\"]\n",
    "        away_team = names[\"away\"]\n",
    "        # meth2: extract match infos (venue,referee,odds)\n",
    "        match_infos = PageExtractor.extract_match_infos(\n",
    "            page,\n",
    "            ScrapingTheGuardian.VENUE_REGEX,\n",
    "            ScrapingTheGuardian.REFEREE_REGEX,\n",
    "            ScrapingTheGuardian.ODDS_REGEX,\n",
    "        )\n",
    "        venue = match_infos[\"venue\"]\n",
    "        referee = match_infos[\"referee\"]\n",
    "        odds = match_infos[\"odds\"]\n",
    "        # meth3: extract text and author of the preview\n",
    "        text_author = PageExtractor.extract_text_authors(page)\n",
    "        text = text_author[\"text\"]\n",
    "        author = text_author[\"author\"]\n",
    "        # meth4: extract preview date\n",
    "        preview_date = PageExtractor.extract_preview_date(page)\n",
    "        # meth5: calculate betting odds\n",
    "        betting_odds = ScrapingTheGuardian.calculate_betting_odds(odds)\n",
    "        # Home team betting odds\n",
    "        odds_home_team = betting_odds[\"odds_home\"]\n",
    "        # Away team betting odds\n",
    "        odds_away_team = betting_odds[\"odds_away\"]\n",
    "        # Draw betting odds\n",
    "        odds_draw = betting_odds[\"odds_draw\"]\n",
    "        # Return preview items\n",
    "        preview_items = dict(\n",
    "            {\n",
    "                \"home_team\": home_team,\n",
    "                \"away_team\": away_team,\n",
    "                \"text\": text,\n",
    "                \"author\": author,\n",
    "                \"venue\": venue,\n",
    "                \"referee\": referee,\n",
    "                \"odds\": odds,\n",
    "                \"odds_home_team\": odds_home_team,\n",
    "                \"odds_away_team\": odds_away_team,\n",
    "                \"odds_draw\": odds_draw,\n",
    "                \"preview_date\": preview_date,\n",
    "            }\n",
    "        )\n",
    "        return preview_items\n",
    "\n",
    "    def extract_previews(self, page: BeautifulSoup) -> List[Dict[str, object]]:\n",
    "        \"\"\"\n",
    "          returns all the information of all browsed previews\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        page: bs4.BeautifulSoup\n",
    "            the html format of the page\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        preview_items: List of (dict of object)\n",
    "\n",
    "        \"\"\"\n",
    "        all_previews_information = []\n",
    "        # We pick all of the match previews on the webpage.\n",
    "        previews = page.findAll(\"div\", {\"class\": \"fc-item__content\"})\n",
    "        # for each preview we extract its information\n",
    "        for preview in previews:\n",
    "            preview_items = {}\n",
    "            # Pick up the preview link\n",
    "            preview_link = preview.find(\"a\")[\"href\"]\n",
    "            # Pick up the match preview page\n",
    "            preview_page = Parser.parse_page(preview_link, self.session)\n",
    "            # We need only Premier League Previews\n",
    "            # To filter previews we need to Find the title of the preview\n",
    "            # Champions league and Cups are not allowed\n",
    "            preview_title = preview_page.find(\"h1\").text\n",
    "            # Check if \"cup\" or \"Champions league\" exists in:\n",
    "            # title, link, preview topic section,preview aside section\n",
    "            # we pick preview topic\n",
    "            try:\n",
    "                preview_topic = preview_page.find(\"div\", {\"class\": \"dcr-lwa3gj\"}).text\n",
    "            except Exception as e:\n",
    "                # some previews in 2009 have different html tags\n",
    "                preview_topic = preview_page.find(\"div\", {\"class\": \"submeta \"}).text\n",
    "            # we pick preview_aside\n",
    "            try:\n",
    "                preview_aside = preview_page.find(\n",
    "                    \"aside\", {\"data-gu-name\": \"title\"}\n",
    "                ).text\n",
    "            except Exception as e:\n",
    "                # some previews in 2009 have different html tags\n",
    "                preview_aside = preview_page.find(\n",
    "                    \"div\", {\"class\": \"content__labels\"}\n",
    "                ).text\n",
    "            # if the preview is not a cup or not for Champions league:\n",
    "            # we proceed the extraction\n",
    "\n",
    "            not_premier_league_found = False\n",
    "            eliminated_matches = [\"Champions League\", \"champions-league\", \"cup\"]\n",
    "            for word in eliminated_matches:\n",
    "                # test if the word in the preview title\n",
    "                if re.search(word, preview_title, re.IGNORECASE):\n",
    "                    not_premier_league_found = True\n",
    "                    break\n",
    "                # test if the word in the preview link\n",
    "                if re.search(word, preview_link, re.IGNORECASE):\n",
    "                    not_premier_league_found = True\n",
    "                    break\n",
    "                # test if the word in the preview topic\n",
    "                if re.search(word, preview_topic, re.IGNORECASE):\n",
    "                    not_premier_league_found = True\n",
    "                    break\n",
    "                # test if the word in the preview aside\n",
    "                if re.search(word, preview_aside, re.IGNORECASE):\n",
    "                    not_premier_league_found = True\n",
    "                    break\n",
    "            # some previews include the type of competition in the text\n",
    "            # we find FA Cup – Kick-off\n",
    "            # so we want to eliminate these previews\n",
    "            cup_in_text = PageExtractor.get_values_matching_regex(\n",
    "                preview_page, \"FA Cup – Kick-off\"\n",
    "            )\n",
    "\n",
    "            if not not_premier_league_found and not cup_in_text:\n",
    "                preview_items = ScrapingTheGuardian.extract_preview_items(\n",
    "                    preview_page, preview_title\n",
    "                )\n",
    "                all_previews_information.append(preview_items)\n",
    "\n",
    "        return all_previews_information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## USE CASE\n",
    "#### scraping only one given page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.theguardian.com/football/series/match-previews?page=140\"\n",
    "scraper = ScrapingTheGuardian()\n",
    "previews_infos = []\n",
    "page = Parser.parse_page(url, scraper.session)\n",
    "previews_infos = scraper.extract_previews(page)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data =pd.DataFrame(previews_infos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>home_team</th>\n",
       "      <th>away_team</th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "      <th>venue</th>\n",
       "      <th>referee</th>\n",
       "      <th>odds</th>\n",
       "      <th>odds_home_team</th>\n",
       "      <th>odds_away_team</th>\n",
       "      <th>odds_draw</th>\n",
       "      <th>preview_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Liverpool</td>\n",
       "      <td>Queens Park Rangers</td>\n",
       "      <td>Try telling Jamie Carragher that nothing is ri...</td>\n",
       "      <td>Andy Hunter</td>\n",
       "      <td>Anfield</td>\n",
       "      <td>Martin Atkinson</td>\n",
       "      <td>[1-4, 12-1, 11-2]</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>6.500000</td>\n",
       "      <td>2013-05-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Chelsea</td>\n",
       "      <td>Everton</td>\n",
       "      <td>This will be the last hurrah for both Rafael B...</td>\n",
       "      <td>Dominic Fifield</td>\n",
       "      <td>Stamford Bridge</td>\n",
       "      <td>Anthony Taylor</td>\n",
       "      <td>[7-10, 9-2, 3-1]</td>\n",
       "      <td>1.700000</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2013-05-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Manchester City</td>\n",
       "      <td>Norwich City</td>\n",
       "      <td>Now that Roberto Mancini has been sacked by Ma...</td>\n",
       "      <td>Jamie Jackson</td>\n",
       "      <td>Carrow Road</td>\n",
       "      <td>Mark Halsey</td>\n",
       "      <td>[4-11, 11-1, 9-2]</td>\n",
       "      <td>1.363636</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>2013-05-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Manchester United</td>\n",
       "      <td>Swansea City</td>\n",
       "      <td>Playing away at Manchester United in the Premi...</td>\n",
       "      <td>Rich Flower</td>\n",
       "      <td>Old Trafford</td>\n",
       "      <td>Jon Moss</td>\n",
       "      <td>[1-3, 11-1, 19-4]</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>5.750000</td>\n",
       "      <td>2013-05-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Stoke City</td>\n",
       "      <td>Tottenham Hotspur</td>\n",
       "      <td>Tottenham travel to the Britannia Stadium to f...</td>\n",
       "      <td>Alex Sutch</td>\n",
       "      <td>Britannia Stadium</td>\n",
       "      <td>Kevin Friend</td>\n",
       "      <td>[7-2, 10-11, 13-5]</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>1.909091</td>\n",
       "      <td>3.600000</td>\n",
       "      <td>2013-05-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Fulham</td>\n",
       "      <td>Liverpool</td>\n",
       "      <td>Four defeats in a row, the most recent of whic...</td>\n",
       "      <td>Sachin Nakrani</td>\n",
       "      <td>Craven Cottage</td>\n",
       "      <td>Mark Halsey</td>\n",
       "      <td>[3-1, 10-11, 13-5]</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.909091</td>\n",
       "      <td>3.600000</td>\n",
       "      <td>2013-05-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Norwich City</td>\n",
       "      <td>West Bromwich Albion</td>\n",
       "      <td>Norwich are not in turmoil, according to their...</td>\n",
       "      <td>Rich Flower</td>\n",
       "      <td>Carrow Road</td>\n",
       "      <td>Howard Webb</td>\n",
       "      <td>[6-5, 5-2, 5-2]</td>\n",
       "      <td>2.200000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>2013-05-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Everton</td>\n",
       "      <td>West Ham United</td>\n",
       "      <td>David Moyes should receive a rousing and emoti...</td>\n",
       "      <td>Andy Hunter</td>\n",
       "      <td>Goodison Park</td>\n",
       "      <td>Mike Jones</td>\n",
       "      <td>[8-15, 13-2, 10-3]</td>\n",
       "      <td>1.533333</td>\n",
       "      <td>7.500000</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>2013-05-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Queens Park Rangers</td>\n",
       "      <td>Newcastle United</td>\n",
       "      <td>Newcastle United felt a little sore that their...</td>\n",
       "      <td>David Hytner</td>\n",
       "      <td>Loftus Road</td>\n",
       "      <td>Lee Probert</td>\n",
       "      <td>[12-5, 13-10, 12-5]</td>\n",
       "      <td>3.400000</td>\n",
       "      <td>2.300000</td>\n",
       "      <td>3.400000</td>\n",
       "      <td>2013-05-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Aston Villa</td>\n",
       "      <td>Chelsea</td>\n",
       "      <td>With Chelsea chasing a top-four finish and Ast...</td>\n",
       "      <td>Stuart James</td>\n",
       "      <td>Villa Park</td>\n",
       "      <td>Lee Mason</td>\n",
       "      <td>[7-2, 10-11, 14-5]</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>1.909091</td>\n",
       "      <td>3.800000</td>\n",
       "      <td>2013-05-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Sunderland</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>Who, back in August, would have guessed that S...</td>\n",
       "      <td>Louise Taylor</td>\n",
       "      <td>Stadium of Light</td>\n",
       "      <td>Mike Dean</td>\n",
       "      <td>[9-5, 15-8, 9-4]</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>2.875000</td>\n",
       "      <td>3.250000</td>\n",
       "      <td>2013-05-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Tottenham Hotspur</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>It has been a good week for Gareth Bale, what ...</td>\n",
       "      <td>David Hytner</td>\n",
       "      <td>White Hart Lane</td>\n",
       "      <td>P Dowd</td>\n",
       "      <td>[4-9, 6-1, 10-3]</td>\n",
       "      <td>1.444444</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>2013-05-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Sunderland</td>\n",
       "      <td>Stoke City</td>\n",
       "      <td>Back in August, Paolo Di Canio, then managing ...</td>\n",
       "      <td>Louise Taylor</td>\n",
       "      <td>Stadium of Light</td>\n",
       "      <td>L Mason</td>\n",
       "      <td>[1-1, 3-1, 11-5]</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.200000</td>\n",
       "      <td>2013-05-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Norwich City</td>\n",
       "      <td>Aston Villa</td>\n",
       "      <td>The focus ahead of this game is on Aston Villa...</td>\n",
       "      <td>Lawrence Ostlere</td>\n",
       "      <td>Carrow Road</td>\n",
       "      <td>K Friend</td>\n",
       "      <td>[7-5, 15-8, 23-10]</td>\n",
       "      <td>2.400000</td>\n",
       "      <td>2.875000</td>\n",
       "      <td>3.300000</td>\n",
       "      <td>2013-05-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>West Bromwich Albion</td>\n",
       "      <td>Wigan Athletic</td>\n",
       "      <td>Wigan's attempt to repeat their perennial esca...</td>\n",
       "      <td>Lawrence Ostlere</td>\n",
       "      <td>The Hawthorns</td>\n",
       "      <td>L Probert</td>\n",
       "      <td>[13-10, 2-1, 12-5]</td>\n",
       "      <td>2.300000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.400000</td>\n",
       "      <td>2013-05-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>West Ham United</td>\n",
       "      <td>Newcastle United</td>\n",
       "      <td>Not many would have predicted at the start of ...</td>\n",
       "      <td>Lawrence Ostlere</td>\n",
       "      <td>Upton Park</td>\n",
       "      <td>C Foy</td>\n",
       "      <td>[13-10, 2-1, 23-10]</td>\n",
       "      <td>2.300000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.300000</td>\n",
       "      <td>2013-05-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Fulham</td>\n",
       "      <td>Reading</td>\n",
       "      <td>This has the distinct feeling of a Premier Lea...</td>\n",
       "      <td>Lawrence Ostlere</td>\n",
       "      <td>Craven Cottage</td>\n",
       "      <td>N Swarbrick</td>\n",
       "      <td>[8-11, 4-1, 13-5]</td>\n",
       "      <td>1.727273</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>3.600000</td>\n",
       "      <td>2013-05-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Queens Park Rangers</td>\n",
       "      <td>Arsenal</td>\n",
       "      <td>The game is up for Queens Park Rangers in the ...</td>\n",
       "      <td>Dominic Fifield</td>\n",
       "      <td>Loftus Road</td>\n",
       "      <td>J Moss</td>\n",
       "      <td>[7-1, 2-5, 7-2]</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1.400000</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>2013-05-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Swansea City</td>\n",
       "      <td>Manchester City</td>\n",
       "      <td>The Capital One Cup hangover appears to have w...</td>\n",
       "      <td>Lawrence Ostlere</td>\n",
       "      <td>Liberty Stadium</td>\n",
       "      <td>M Jones</td>\n",
       "      <td>[15-4, 3-4, 13-5]</td>\n",
       "      <td>4.750000</td>\n",
       "      <td>1.750000</td>\n",
       "      <td>3.600000</td>\n",
       "      <td>2013-05-03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               home_team             away_team  \\\n",
       "0              Liverpool   Queens Park Rangers   \n",
       "1                Chelsea               Everton   \n",
       "2        Manchester City          Norwich City   \n",
       "3      Manchester United          Swansea City   \n",
       "4             Stoke City     Tottenham Hotspur   \n",
       "5                 Fulham             Liverpool   \n",
       "6           Norwich City  West Bromwich Albion   \n",
       "7                Everton       West Ham United   \n",
       "8    Queens Park Rangers      Newcastle United   \n",
       "9            Aston Villa               Chelsea   \n",
       "10            Sunderland           Southampton   \n",
       "11     Tottenham Hotspur           Southampton   \n",
       "12            Sunderland            Stoke City   \n",
       "13          Norwich City           Aston Villa   \n",
       "14  West Bromwich Albion        Wigan Athletic   \n",
       "15       West Ham United      Newcastle United   \n",
       "16                Fulham               Reading   \n",
       "17   Queens Park Rangers               Arsenal   \n",
       "18          Swansea City       Manchester City   \n",
       "\n",
       "                                                 text            author  \\\n",
       "0   Try telling Jamie Carragher that nothing is ri...       Andy Hunter   \n",
       "1   This will be the last hurrah for both Rafael B...   Dominic Fifield   \n",
       "2   Now that Roberto Mancini has been sacked by Ma...     Jamie Jackson   \n",
       "3   Playing away at Manchester United in the Premi...       Rich Flower   \n",
       "4   Tottenham travel to the Britannia Stadium to f...        Alex Sutch   \n",
       "5   Four defeats in a row, the most recent of whic...    Sachin Nakrani   \n",
       "6   Norwich are not in turmoil, according to their...       Rich Flower   \n",
       "7   David Moyes should receive a rousing and emoti...       Andy Hunter   \n",
       "8   Newcastle United felt a little sore that their...      David Hytner   \n",
       "9   With Chelsea chasing a top-four finish and Ast...      Stuart James   \n",
       "10  Who, back in August, would have guessed that S...     Louise Taylor   \n",
       "11  It has been a good week for Gareth Bale, what ...      David Hytner   \n",
       "12  Back in August, Paolo Di Canio, then managing ...     Louise Taylor   \n",
       "13  The focus ahead of this game is on Aston Villa...  Lawrence Ostlere   \n",
       "14  Wigan's attempt to repeat their perennial esca...  Lawrence Ostlere   \n",
       "15  Not many would have predicted at the start of ...  Lawrence Ostlere   \n",
       "16  This has the distinct feeling of a Premier Lea...  Lawrence Ostlere   \n",
       "17  The game is up for Queens Park Rangers in the ...   Dominic Fifield   \n",
       "18  The Capital One Cup hangover appears to have w...  Lawrence Ostlere   \n",
       "\n",
       "                venue          referee                 odds  odds_home_team  \\\n",
       "0             Anfield  Martin Atkinson    [1-4, 12-1, 11-2]        1.250000   \n",
       "1     Stamford Bridge   Anthony Taylor     [7-10, 9-2, 3-1]        1.700000   \n",
       "2         Carrow Road      Mark Halsey    [4-11, 11-1, 9-2]        1.363636   \n",
       "3        Old Trafford         Jon Moss    [1-3, 11-1, 19-4]        1.333333   \n",
       "4   Britannia Stadium     Kevin Friend   [7-2, 10-11, 13-5]        4.500000   \n",
       "5      Craven Cottage      Mark Halsey   [3-1, 10-11, 13-5]        4.000000   \n",
       "6         Carrow Road      Howard Webb      [6-5, 5-2, 5-2]        2.200000   \n",
       "7       Goodison Park       Mike Jones   [8-15, 13-2, 10-3]        1.533333   \n",
       "8         Loftus Road      Lee Probert  [12-5, 13-10, 12-5]        3.400000   \n",
       "9          Villa Park        Lee Mason   [7-2, 10-11, 14-5]        4.500000   \n",
       "10   Stadium of Light        Mike Dean     [9-5, 15-8, 9-4]        2.800000   \n",
       "11    White Hart Lane           P Dowd     [4-9, 6-1, 10-3]        1.444444   \n",
       "12   Stadium of Light          L Mason     [1-1, 3-1, 11-5]        2.000000   \n",
       "13        Carrow Road         K Friend   [7-5, 15-8, 23-10]        2.400000   \n",
       "14      The Hawthorns        L Probert   [13-10, 2-1, 12-5]        2.300000   \n",
       "15         Upton Park            C Foy  [13-10, 2-1, 23-10]        2.300000   \n",
       "16     Craven Cottage      N Swarbrick    [8-11, 4-1, 13-5]        1.727273   \n",
       "17        Loftus Road           J Moss      [7-1, 2-5, 7-2]        8.000000   \n",
       "18    Liberty Stadium          M Jones    [15-4, 3-4, 13-5]        4.750000   \n",
       "\n",
       "    odds_away_team  odds_draw preview_date  \n",
       "0        13.000000   6.500000   2013-05-17  \n",
       "1         5.500000   4.000000   2013-05-17  \n",
       "2        12.000000   5.500000   2013-05-17  \n",
       "3        12.000000   5.750000   2013-05-10  \n",
       "4         1.909091   3.600000   2013-05-10  \n",
       "5         1.909091   3.600000   2013-05-10  \n",
       "6         3.500000   3.500000   2013-05-10  \n",
       "7         7.500000   4.333333   2013-05-10  \n",
       "8         2.300000   3.400000   2013-05-10  \n",
       "9         1.909091   3.800000   2013-05-10  \n",
       "10        2.875000   3.250000   2013-05-10  \n",
       "11        7.000000   4.333333   2013-05-03  \n",
       "12        4.000000   3.200000   2013-05-03  \n",
       "13        2.875000   3.300000   2013-05-03  \n",
       "14        3.000000   3.400000   2013-05-03  \n",
       "15        3.000000   3.300000   2013-05-03  \n",
       "16        5.000000   3.600000   2013-05-03  \n",
       "17        1.400000   4.500000   2013-05-03  \n",
       "18        1.750000   3.600000   2013-05-03  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scraping all pages"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "url = \"https://www.theguardian.com/football/series/match-previews\"\n",
    "scraper = ScrapingTheGuardian()\n",
    "all_previews =[]\n",
    "last_page = False\n",
    "while last_page == False : \n",
    "    page = Parser.parse_page(url,scraper.session)\n",
    "    previews_infos = scraper.extract_previews(page)\n",
    "    all_previews.append(previews_infos)\n",
    "    url, last_page = Parser.get_next_page(page)\n",
    "    # wait 20s\n",
    "    sleep(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
