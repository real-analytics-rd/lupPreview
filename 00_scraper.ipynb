{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp scraper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Guardian Scraper\n",
    "\n",
    "> Scraping Premier League Previews from the Guardian."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To reach the aim of our project, we have begun the first task, which is to collect football experts' comments and data from English Premier League matches.\n",
    "<br>For this task, we will use match previews from \"The Guardian.\" It goes back far enough, from 2009 to today, to allow us to integrate deep neural networks.\n",
    "<br>Indeed, \"The Guardian's\" football experts publish previews every week, usually two or three days before the matches.\n",
    "<br>In this regard, we began by creating a data extraction tool that will allow us to extract this information on a regular basis.\n",
    "<br>The information to be extracted is as follows:\n",
    "\n",
    "- The names of the competing teams.\n",
    "- The date of the game\n",
    "- The identity of the referee\n",
    "- The stadium's name\n",
    "- Sports odds that will be converted to decimal format\n",
    "- The football expert's text\n",
    "- The text's author.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A preliminary examination of the Guardian's website"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-size: 200px\">\n",
    "    \n",
    "|            Issues                 |          Solutions          |\n",
    "|------------------------------     |-------------------|\n",
    "|   4 possible formats for previews(old format, new format,Cup's format and a particular format) |Select the appropriate html tags|\n",
    "|   Preview titles are not the same ( we can find Squad Sheets or match preview)|Pick only the names of the teams and eliminate the rest|\n",
    "|   The date of the match is not always available |Pick the preview date|\n",
    "|   The order of the elements and labels are not the same |Using regex patterns to get information|\n",
    "|   Missing values for betting odds |We treat the general case separately and we set up specific regex patterns for these particular cases|\n",
    "|   Odds format is different|We treat the general case separately and we set up specific regex patterns for these particular cases|\n",
    "|   We can find non-numeric values for Odds like (Evens,evens,Eve,odds-on)|Replace evens by 1-1|\n",
    "|   There are some previews that don't have author and text|For previews that have no text, we put None (not available)|\n",
    "|   The existence of previews for the FA CUP,Carabao Cup,Champions league,World Cup|Filter previews by checking if the match exists in \"Opta\" database, and pick only Premier League match |\n",
    "|   We are not sure if the names of the teams are the same as the ones in Opta|Set up a dictionary or check manually to map teams to their IDs|\n",
    "|When we send many requests, the guardian server blocks your IP address, which is interpreted as a DDOS attack|Do a sleep of a random x seconds between requests or change IP address and work with rotating proxy|\n",
    "</div >\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries and Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "import pandas as pd\n",
    "import dateparser\n",
    "import random\n",
    "import requests\n",
    "import logging\n",
    "from guardian_scraper.Db_Config import *\n",
    "from guardian_scraper.parser import *\n",
    "from guardian_scraper.extractor import *\n",
    "from guardian_scraper.mapper import *\n",
    "from guardian_scraper.models.preview import *\n",
    "from typing import Dict, Union\n",
    "from requests_html import HTMLSession\n",
    "from bs4 import BeautifulSoup\n",
    "from time import sleep\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ScrapingTheGuardian Class\n",
    "\n",
    "##### This class represents a scraper from the \"Guardian\" website and has 4 functions:\n",
    "\n",
    "1- <b> calculate_betting_odds </b> returns decimal odds.\n",
    "\n",
    "&emsp;In this section, we will calculate the odds derived from the football preview.\n",
    "<br>&emsp;Considering the following example:\n",
    "<br>&emsp;&emsp; [\"9-20\",\"29-5\",\"6-5\"] \n",
    "<br>&emsp;&emsp;We calculate each sport's rating separately using the following formula:\n",
    "<br>&emsp;&emsp;&emsp; home = (9/20) + 1 \n",
    "<br>&emsp;&emsp;&emsp; away = (29/5) + 1\n",
    "<br>&emsp;&emsp;&emsp; draw = (6/5) + 1\n",
    "<br>&emsp;If we were successful in obtaining decimal odds, they will be returned in a Python dictionary.<br>&emsp;Otherwise, the values will be None (Not available).\n",
    "\n",
    "\n",
    "2- <b> extract_preview_items </b>returns the entire contents of a football preview.\n",
    "\n",
    "&emsp;In this section, we will call the functions defined in the PageExtractor class and return a Python dictionary containing all of this information.\n",
    "<br>&emsp;But first, we use the <b>calculate_betting_odds</b> function to calculate the sports odds for the home team's victory, the away team's victory, and a draw.\n",
    "\n",
    "\"game Id\",\"home team\",\"away team\",\"text\",\"author\",\"venue\",\"referee\",\"odds\",\"odds home team\",\"odds away team\",\"odds draw\", \"preview date\",\"game Date\",\"preview_link\" are the returned values.\n",
    "\n",
    "3- <b> extract_previews </b> returns the information of all extracted previews.\n",
    "\n",
    "&emsp;We retrieve all previews for a given page and go through them one by one, taking the link and getting its data using the \"Guardian Api.\"\n",
    "<br>&emsp;If the \"Guardian Api\" does not work, we will resort to the traditional process of html parsing. \n",
    "<br>&emsp;For each preview in the data extracted from the Guardian, we will look for the id of the home team and the away team and match it with the <b>opta.fixture</b><br>&emsp;database to get the gameID and gameDate and finally we save it in a MongoDb collection.\n",
    "<br>&emsp;If the game exists, we will proceed with the data extraction.\n",
    "The previous function, <b>extract_preview_items</b>, will be called here to extract information from <br>&emsp;each \n",
    "preview, which will then be stored in the list \"all previews.\"\n",
    "<br>&emsp;However, we will only extract previews that do not already exist in the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class ScrapingTheGuardian:\n",
    "    \"\"\"\n",
    "    A class to represent a scraper from the \"Guardian\" website.\n",
    "\n",
    "    ...\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    session : requests_html.HTMLSession\n",
    "        a web session\n",
    "    VENUE_REGEX : str\n",
    "        venue regex expression\n",
    "    REFEREE_REGEX : str\n",
    "        referee regex expression\n",
    "    ODDS_REGEX : str\n",
    "        odds regex expression\n",
    "\n",
    "    Methods\n",
    "    -------\n",
    "    calculate_betting_odds(odds)\n",
    "        returns decimal odds.\n",
    "    extract_preview_items(content,link,preview_date,game_date,game_id,home_team,away_team)\n",
    "        returns all information of a football preview.\n",
    "    extract_previews(self,page,previews_last_date,last_preview,all_previews,df_teams)\n",
    "        returns the information of all extracted previews.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # venue, referee, odds pattern regex\n",
    "    # in some previews, all of the information is on the same line.\n",
    "    VENUE_REGEX = \"Venue(.*)Tickets|Venue(.*),|Venue(.*)\"\n",
    "    REFEREE_REGEX = \"Referee(.*)This season|Referee(.*)Last season's|Referee(.*)Odds|Referee[\\s](.*)|Ref(.*)Odds\"\n",
    "    # {Odds H 11-8 A 11-8 D 11-8}\n",
    "    # {Odds Liverpool 11-8 Aston Villa 11-8 Draw 11-8}\n",
    "    # missing label {Odds H 11-8 11-8 D 11-8}\n",
    "    # missing value {Odds H 11-8 A 11-8}\n",
    "    ODDS_REGEX = \"Odds[\\s]*[a-zA-Z' ]*(\\d{1,3}-[\\s]*\\d{1,3})[\\s]*[a-zA-Z' ]*(\\d{1,3}-[\\s]*\\d{1,3})([\\s]*[a-zA-Z']*[\\s]*(\\d{1,3}-[\\s]*\\d{1,3}))*\"\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        # Initialize session to start scraping\n",
    "        self.session = HTMLSession()\n",
    "\n",
    "    @staticmethod\n",
    "    def calculate_betting_odds(odds: list) -> Dict[str, object]:\n",
    "        \"\"\"\n",
    "          returns decimal odds.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        odds: list of str\n",
    "            odds values\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        betting_odds: dict of object\n",
    "\n",
    "        \"\"\"\n",
    "        # Initialize betting odds to n/a (not available)\n",
    "        # Some previews may not include odds\n",
    "        odds_home = None\n",
    "        odds_away = None\n",
    "        odds_draw = None\n",
    "\n",
    "        if odds is not None:  # If odds exist\n",
    "            # example of odds:\n",
    "            # {H 4-6 A 43-10 D 3-1}\n",
    "            # {liverpool 4-6 Tottenham 43-10 Draw 3-1}\n",
    "            # {H 4-6 43-10 D 3-1}\n",
    "            # {H 4-6 A 43-10}\n",
    "            # The formula will be (4/6)+1 , (43/10)+1 , (3/1)+1\n",
    "            # Home team odds\n",
    "            betting_odds_home = odds[0]\n",
    "            try:\n",
    "                odds_home = (\n",
    "                    int(betting_odds_home.split(\"-\")[0])\n",
    "                    / int(betting_odds_home.split(\"-\")[1])\n",
    "                ) + 1\n",
    "            except ZeroDivisionError:\n",
    "                logging.error(\"Home team odds are wrong\")\n",
    "                pass\n",
    "            # Away team odds\n",
    "            betting_odds_away = odds[1]\n",
    "            try:\n",
    "                odds_away = (\n",
    "                    int(betting_odds_away.split(\"-\")[0])\n",
    "                    / int(betting_odds_away.split(\"-\")[1])\n",
    "                ) + 1\n",
    "            except ZeroDivisionError:\n",
    "                logging.error(\"Away team odds are wrong\")\n",
    "                pass\n",
    "            # if we have the normal format of odds\n",
    "            # we will have 3 parts(odds_home,odds_away,odds_draw)\n",
    "            if len(odds) >= 3:\n",
    "                odds.pop(2)\n",
    "                # Draw odds\n",
    "                betting_odds_draw = odds[2]\n",
    "                try:\n",
    "                    odds_draw = (\n",
    "                        int(betting_odds_draw.split(\"-\")[0])\n",
    "                        / int(betting_odds_draw.split(\"-\")[1])\n",
    "                    ) + 1\n",
    "                except ZeroDivisionError:\n",
    "                    logging.error(\"Draw odds are wrong\")\n",
    "                    pass\n",
    "\n",
    "        betting_odds = dict(\n",
    "            {\"odds_home\": odds_home, \"odds_away\": odds_away, \"odds_draw\": odds_draw}\n",
    "        )\n",
    "        return betting_odds\n",
    "\n",
    "    @staticmethod\n",
    "    def extract_preview_items(\n",
    "        content: BeautifulSoup,\n",
    "        link: str,\n",
    "        preview_date: datetime,\n",
    "        game_date: datetime,\n",
    "        game_id: int,\n",
    "        home_team: str,\n",
    "        away_team: str,\n",
    "        response_type: str,\n",
    "    ) -> Dict[str, object]:\n",
    "        \"\"\"\n",
    "          returns all information of a football preview\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        content: bs4.BeautifulSoup\n",
    "            the html format of the preview content\n",
    "        link: str\n",
    "            the link of the preview\n",
    "        preview_date: datetime\n",
    "            the preview date\n",
    "        game_date: datetime\n",
    "            the game date\n",
    "        game_id: int\n",
    "            the game id\n",
    "        home_team: str\n",
    "            the home team name\n",
    "        away_team: str\n",
    "            the away team name\n",
    "        response_type: str\n",
    "            the parsing method('api' or 'html')\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        preview_items: dict of object\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        # meth1: extract match infos (venue,referee,odds)\n",
    "        match_infos = PageExtractor.extract_match_infos(\n",
    "            content,\n",
    "            response_type,\n",
    "            ScrapingTheGuardian.VENUE_REGEX,\n",
    "            ScrapingTheGuardian.REFEREE_REGEX,\n",
    "            ScrapingTheGuardian.ODDS_REGEX,\n",
    "        )\n",
    "        venue = match_infos[\"venue\"]\n",
    "        referee = match_infos[\"referee\"]\n",
    "        odds = match_infos[\"odds\"]\n",
    "        # meth2: extract text and author of the preview\n",
    "        text_author = PageExtractor.extract_text_authors(content, response_type)\n",
    "        text = text_author[\"text\"]\n",
    "        author = text_author[\"author\"]\n",
    "        # meth3: calculate betting odds\n",
    "        betting_odds = ScrapingTheGuardian.calculate_betting_odds(odds)\n",
    "        # Home team betting odds\n",
    "        odds_home_team = betting_odds[\"odds_home\"]\n",
    "        # Away team betting odds\n",
    "        odds_away_team = betting_odds[\"odds_away\"]\n",
    "        # Draw betting odds\n",
    "        odds_draw = betting_odds[\"odds_draw\"]\n",
    "        # Return preview items\n",
    "        preview_items = dict(\n",
    "            {\n",
    "                \"game_id\": game_id,\n",
    "                \"home_team\": home_team,\n",
    "                \"away_team\": away_team,\n",
    "                \"text\": text,\n",
    "                \"author\": author,\n",
    "                \"venue\": venue,\n",
    "                \"referee\": referee,\n",
    "                \"odds\": odds,\n",
    "                \"odds_home_team\": odds_home_team,\n",
    "                \"odds_away_team\": odds_away_team,\n",
    "                \"odds_draw\": odds_draw,\n",
    "                \"preview_date\": preview_date,\n",
    "                \"game_date\": game_date,\n",
    "                \"preview_link\": link,\n",
    "            }\n",
    "        )\n",
    "        return preview_items\n",
    "\n",
    "    def extract_previews(\n",
    "        self,\n",
    "        page: BeautifulSoup,\n",
    "        previews_last_date: datetime,\n",
    "        last_preview: bool,\n",
    "        all_previews: list,\n",
    "        df_teams: pd.DataFrame,\n",
    "    ) -> Union[bool, list]:\n",
    "        \"\"\"\n",
    "          save all browsed previews in local\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        page: bs4.BeautifulSoup\n",
    "            the html format of the page\n",
    "        previews_last_date : datetime\n",
    "            the last extracted preview date in the database\n",
    "        last_preview: bool\n",
    "            an indicator to know when we should stop the scraper\n",
    "        all_previews: list\n",
    "            a list that contains all extracted previews\n",
    "        df_teams: pd.DataFrame\n",
    "            a dataframe that contains teams and their different names\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        bool\n",
    "\n",
    "        \"\"\"\n",
    "        # We pick all of the match previews on the webpage.\n",
    "        previews = page.findAll(\"div\", {\"class\": \"fc-item__content\"})\n",
    "        # for each preview we extract its information.\n",
    "        for preview in previews:\n",
    "            # we pick the preview date and we parse it in a date format\n",
    "            preview_date = preview.find(\"time\")[\"datetime\"]\n",
    "            preview_date = dateparser.parse(preview_date, settings={\"TIMEZONE\": \"UTC\"})\n",
    "            # if the date selected from the previews database exists\n",
    "            # and has been reached by the preview date, we stop the loop\n",
    "            # and mark last_preview as True.\n",
    "            if previews_last_date and preview_date.date() <= previews_last_date.date():\n",
    "                logging.info(\"The scraper turned off\")\n",
    "                last_preview = True\n",
    "                break\n",
    "            # Pick the preview link\n",
    "            preview_link = preview.find(\"a\")[\"href\"]\n",
    "\n",
    "            # We extract the last part of the link, which corresponds to the preview api link\n",
    "            api_preview_url = preview_link.replace(\"https://www.theguardian.com\", \"\")\n",
    "            # request the api\n",
    "            response = requests.get(\n",
    "                \"https://content.guardianapis.com/\"\n",
    "                + api_preview_url\n",
    "                + \"?api-key=fd4452e9-76a5-45a1-b30d-bdd156640b9c&show-blocks=all\"\n",
    "            )\n",
    "            # if the api works we get the title and the content of the preview\n",
    "            # else we extract html contents\n",
    "            if response:\n",
    "                logging.info(\"The Guardian Api works\")\n",
    "                # get the preview data\n",
    "                data = response.json()\n",
    "                # preview title\n",
    "                preview_title = data[\"response\"][\"content\"][\"webTitle\"]\n",
    "                # preview content\n",
    "                preview_content = BeautifulSoup(\n",
    "                    data[\"response\"][\"content\"][\"blocks\"][\"body\"][0][\"bodyHtml\"],\n",
    "                    \"html.parser\",\n",
    "                )\n",
    "                # preview date\n",
    "                preview_date = data[\"response\"][\"content\"][\"webPublicationDate\"]\n",
    "                preview_date = dateparser.parse(\n",
    "                    preview_date, settings={\"TIMEZONE\": \"UTC\"}\n",
    "                )\n",
    "                response_type = \"api\"\n",
    "\n",
    "            else:\n",
    "                logging.info(\"The Guardian Api does not work\")\n",
    "                preview_content = Parser.parse_page(preview_link, self.session)\n",
    "                preview_title = preview_content.find(\"h1\").text\n",
    "                response_type = \"html\"\n",
    "\n",
    "            # extract team names\n",
    "            names = PageExtractor.extract_teams_names(preview_title)\n",
    "            # Home team and  Away Team\n",
    "            home_team = names[\"home\"]\n",
    "            away_team = names[\"away\"]\n",
    "            # get teams id\n",
    "            home_team_id = PreviewsMapping.get_team_id(home_team, df_teams)\n",
    "            away_team_id = PreviewsMapping.get_team_id(away_team, df_teams)\n",
    "            # pick the preview date\n",
    "            # get the id and the date of the game\n",
    "            game = PreviewsMapping.get_game_id_date(\n",
    "                home_team_id, away_team_id, preview_date\n",
    "            )\n",
    "            # if the game exists we extract the preview information\n",
    "            if game != None:\n",
    "                preview_infos = ScrapingTheGuardian.extract_preview_items(\n",
    "                    preview_content,\n",
    "                    preview_link,\n",
    "                    preview_date,\n",
    "                    game.gameDate,\n",
    "                    game.gameId,\n",
    "                    home_team,\n",
    "                    away_team,\n",
    "                    response_type,\n",
    "                )\n",
    "                logging.info(\"Returned Preview information: {}\".format(preview_infos))\n",
    "                # connect to database\n",
    "                mongoengine_client = MongoClient.connect(\"1\")\n",
    "                # preview class\n",
    "                preview = Previews(\n",
    "                    gameId=preview_infos[\"game_id\"],\n",
    "                    homeTeam=preview_infos[\"home_team\"],\n",
    "                    awayTeam=preview_infos[\"away_team\"],\n",
    "                    text=preview_infos[\"text\"],\n",
    "                    author=preview_infos[\"author\"],\n",
    "                    venue=preview_infos[\"venue\"],\n",
    "                    referee=preview_infos[\"referee\"],\n",
    "                    odds=preview_infos[\"odds\"],\n",
    "                    oddsHomeTeam=preview_infos[\"odds_home_team\"],\n",
    "                    oddsAwayTeam=preview_infos[\"odds_away_team\"],\n",
    "                    oddsDraw=preview_infos[\"odds_draw\"],\n",
    "                    gameDate=preview_infos[\"game_date\"],\n",
    "                    previewDate=preview_infos[\"preview_date\"],\n",
    "                    previewLink=preview_infos[\"preview_link\"],\n",
    "                )\n",
    "                # Validate and save input raw data\n",
    "                MongoClient.save(preview)\n",
    "                all_previews.append(preview_infos)\n",
    "\n",
    "            else:\n",
    "                logging.info(\n",
    "                    \"The game {} does not exist in the Opta database\".format(\n",
    "                        preview_title\n",
    "                    )\n",
    "                )\n",
    "\n",
    "        return last_preview, all_previews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scraping all pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store scraper actions in a log file\n",
    "logging.basicConfig(\n",
    "    filename=\"scraper.log\", level=logging.INFO, format=\"%(levelname)s:%(message)s\"\n",
    ")\n",
    "# starting url\n",
    "url = \"https://www.theguardian.com/football/series/match-previews\"\n",
    "# initialize the scraper instance.\n",
    "scraper = ScrapingTheGuardian()\n",
    "# initially we are not at the last page.\n",
    "last_page = False\n",
    "# we'll extract the previews that haven't already been extracted.\n",
    "last_preview = False\n",
    "# we specify the last preview date in the previews collection on which the scraper will be turned off.\n",
    "mongoengine_client = MongoClient.connect(\"1\")\n",
    "previews_last_date = Previews.objects().order_by(\"-previewDate\", \"-gameDate\").first()\n",
    "\n",
    "# if the database is empty we will scrap all pages\n",
    "if previews_last_date != None:\n",
    "    last_previews_date = previews_last_date.previewDate\n",
    "else:\n",
    "    last_previews_date = None\n",
    "\n",
    "logging.info(\"The last preview date stored in the database is: {}\".format(last_previews_date))\n",
    "all_previews = []\n",
    "# charging teams dictionary\n",
    "df_teams = pd.read_csv(\".//datasets//final_data.csv\")\n",
    "# if we are not at the last page\n",
    "# and we haven't reached an extracted preview\n",
    "# we launch the scraper\n",
    "while not last_page and not last_preview:\n",
    "    # a random timer\n",
    "    time = random.randint(2, 60)\n",
    "    logging.info(\"The scraper will wait {} seconds ...\".format(time))\n",
    "    logging.info(\"The scraper will open this url: {}\".format(url))\n",
    "    # wait time seconds\n",
    "    sleep(time)\n",
    "    # get the html format of the page containing previews\n",
    "    page = Parser.parse_page(url, scraper.session)\n",
    "    # launch the scraper , extract previews information\n",
    "    last_preview, all_previews = scraper.extract_previews(\n",
    "        page, last_previews_date, last_preview, all_previews, df_teams\n",
    "    )\n",
    "    # get the url of the following page and verify if we are at the last page\n",
    "    url, last_page = Parser.get_next_page(page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(all_previews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>game_id</th>\n",
       "      <th>home_team</th>\n",
       "      <th>away_team</th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "      <th>venue</th>\n",
       "      <th>referee</th>\n",
       "      <th>odds</th>\n",
       "      <th>odds_home_team</th>\n",
       "      <th>odds_away_team</th>\n",
       "      <th>odds_draw</th>\n",
       "      <th>preview_date</th>\n",
       "      <th>game_date</th>\n",
       "      <th>preview_link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>987815</td>\n",
       "      <td>Huddersfield</td>\n",
       "      <td>Manchester City</td>\n",
       "      <td>Most Huddersfield fans were sad to see David W...</td>\n",
       "      <td>Paul Doyle</td>\n",
       "      <td>John Smith’s Stadium</td>\n",
       "      <td>Andre Marriner</td>\n",
       "      <td>[22-1, 1-6, 8-1]</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>1.166667</td>\n",
       "      <td>9.00</td>\n",
       "      <td>2019-01-19 09:00:12+00:00</td>\n",
       "      <td>2019-01-20 13:30:00</td>\n",
       "      <td>https://www.theguardian.com/football/2019/jan/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>987818</td>\n",
       "      <td>Newcastle United</td>\n",
       "      <td>Cardiff</td>\n",
       "      <td>There is little love lost between Rafa Benítez...</td>\n",
       "      <td>Louise Taylor</td>\n",
       "      <td>St James’ Park</td>\n",
       "      <td>Stuart Atwell</td>\n",
       "      <td>[1-1, 10-3, 12-5]</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>3.40</td>\n",
       "      <td>2019-01-18 16:57:35+00:00</td>\n",
       "      <td>2019-01-19 15:00:00</td>\n",
       "      <td>https://www.theguardian.com/football/2019/jan/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>987821</td>\n",
       "      <td>Wolverhampton Wanderers</td>\n",
       "      <td>Leicester</td>\n",
       "      <td>Wolves have lost five of their last seven matc...</td>\n",
       "      <td>Graham Searles</td>\n",
       "      <td>Molineux</td>\n",
       "      <td>Chris Kavanagh</td>\n",
       "      <td>[6-5, 5-2, 2-1]</td>\n",
       "      <td>2.200000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>3.00</td>\n",
       "      <td>2019-01-18 16:19:44+00:00</td>\n",
       "      <td>2019-01-19 12:30:00</td>\n",
       "      <td>https://www.theguardian.com/football/2019/jan/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>987820</td>\n",
       "      <td>Watford</td>\n",
       "      <td>Burnley</td>\n",
       "      <td>Watford and Burnley are unbeaten since Boxing ...</td>\n",
       "      <td>Graham Searles</td>\n",
       "      <td>Vicarage Road</td>\n",
       "      <td>Michael Oliver</td>\n",
       "      <td>[4-6, 5-1, 3-1]</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>4.00</td>\n",
       "      <td>2019-01-18 15:15:04+00:00</td>\n",
       "      <td>2019-01-19 15:00:00</td>\n",
       "      <td>https://www.theguardian.com/football/2019/jan/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>987817</td>\n",
       "      <td>Manchester United</td>\n",
       "      <td>Brighton</td>\n",
       "      <td>If Manchester United can reel off the seventh ...</td>\n",
       "      <td>Jamie Jackson</td>\n",
       "      <td>Old Trafford</td>\n",
       "      <td>Paul Tierney</td>\n",
       "      <td>[1-3, 12-1, 5-1]</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>6.00</td>\n",
       "      <td>2019-01-18 14:23:22+00:00</td>\n",
       "      <td>2019-01-19 15:00:00</td>\n",
       "      <td>https://www.theguardian.com/football/2019/jan/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3063</th>\n",
       "      <td>284023</td>\n",
       "      <td>Fulham</td>\n",
       "      <td>Chelsea</td>\n",
       "      <td>The achievements of Fulham, who came seventh l...</td>\n",
       "      <td>Kevin McCarra</td>\n",
       "      <td>Craven Cottage</td>\n",
       "      <td>A Marriner</td>\n",
       "      <td>[9-2, 4-7, 5-2]</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>1.571429</td>\n",
       "      <td>3.50</td>\n",
       "      <td>2009-08-21 21:24:27+00:00</td>\n",
       "      <td>2009-08-23 15:00:00</td>\n",
       "      <td>https://www.theguardian.com/football/2009/aug/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3064</th>\n",
       "      <td>284022</td>\n",
       "      <td>Burnley</td>\n",
       "      <td>Everton</td>\n",
       "      <td>Turf Moor thrived on its first top-flight game...</td>\n",
       "      <td>Andy Hunter</td>\n",
       "      <td>Turf Moor, Saturday</td>\n",
       "      <td>P Dowd</td>\n",
       "      <td>[2-1, 6-5, 11-5]</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.200000</td>\n",
       "      <td>3.20</td>\n",
       "      <td>2009-08-21 21:21:25+00:00</td>\n",
       "      <td>2009-08-23 14:00:00</td>\n",
       "      <td>https://www.theguardian.com/football/2009/aug/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3065</th>\n",
       "      <td>284021</td>\n",
       "      <td>Birmingham City</td>\n",
       "      <td>Stoke City</td>\n",
       "      <td>If Birmingham are to stay in the Premier Leagu...</td>\n",
       "      <td>David Lacey</td>\n",
       "      <td>St Andrew's, Saturday</td>\n",
       "      <td>C Foy</td>\n",
       "      <td>[23-20, 21-10, 11-5]</td>\n",
       "      <td>2.150000</td>\n",
       "      <td>3.100000</td>\n",
       "      <td>3.20</td>\n",
       "      <td>2009-08-21 21:15:59+00:00</td>\n",
       "      <td>2009-08-22 14:00:00</td>\n",
       "      <td>https://www.theguardian.com/football/2009/aug/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3066</th>\n",
       "      <td>284020</td>\n",
       "      <td>Arsenal</td>\n",
       "      <td>Portsmouth</td>\n",
       "      <td>Peter Storrie says he has a mystery new backer...</td>\n",
       "      <td>David Hytner</td>\n",
       "      <td>Emirates Stadium, Saturday</td>\n",
       "      <td>S Bennett</td>\n",
       "      <td>[1-6, 12-1, 5-1]</td>\n",
       "      <td>1.166667</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>6.00</td>\n",
       "      <td>2009-08-21 21:13:41+00:00</td>\n",
       "      <td>2009-08-22 14:00:00</td>\n",
       "      <td>https://www.theguardian.com/football/2009/aug/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3067</th>\n",
       "      <td>284027</td>\n",
       "      <td>Sunderland</td>\n",
       "      <td>Blackburn Rovers</td>\n",
       "      <td>As a former Newcastle United manager, Blackbur...</td>\n",
       "      <td>Louise Taylor</td>\n",
       "      <td>Stadium of Light, Saturday</td>\n",
       "      <td>A Wiley</td>\n",
       "      <td>[1-1, 12-5, 9-4]</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.400000</td>\n",
       "      <td>3.25</td>\n",
       "      <td>2009-08-21 21:08:35+00:00</td>\n",
       "      <td>2009-08-22 14:00:00</td>\n",
       "      <td>https://www.theguardian.com/football/2009/aug/...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3068 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      game_id                home_team         away_team  \\\n",
       "0      987815             Huddersfield   Manchester City   \n",
       "1      987818         Newcastle United           Cardiff   \n",
       "2      987821  Wolverhampton Wanderers         Leicester   \n",
       "3      987820                  Watford           Burnley   \n",
       "4      987817        Manchester United          Brighton   \n",
       "...       ...                      ...               ...   \n",
       "3063   284023                   Fulham           Chelsea   \n",
       "3064   284022                  Burnley           Everton   \n",
       "3065   284021          Birmingham City        Stoke City   \n",
       "3066   284020                  Arsenal        Portsmouth   \n",
       "3067   284027               Sunderland  Blackburn Rovers   \n",
       "\n",
       "                                                   text          author  \\\n",
       "0     Most Huddersfield fans were sad to see David W...      Paul Doyle   \n",
       "1     There is little love lost between Rafa Benítez...   Louise Taylor   \n",
       "2     Wolves have lost five of their last seven matc...  Graham Searles   \n",
       "3     Watford and Burnley are unbeaten since Boxing ...  Graham Searles   \n",
       "4     If Manchester United can reel off the seventh ...   Jamie Jackson   \n",
       "...                                                 ...             ...   \n",
       "3063  The achievements of Fulham, who came seventh l...   Kevin McCarra   \n",
       "3064  Turf Moor thrived on its first top-flight game...     Andy Hunter   \n",
       "3065  If Birmingham are to stay in the Premier Leagu...     David Lacey   \n",
       "3066  Peter Storrie says he has a mystery new backer...    David Hytner   \n",
       "3067  As a former Newcastle United manager, Blackbur...   Louise Taylor   \n",
       "\n",
       "                           venue         referee                  odds  \\\n",
       "0           John Smith’s Stadium  Andre Marriner      [22-1, 1-6, 8-1]   \n",
       "1                 St James’ Park   Stuart Atwell     [1-1, 10-3, 12-5]   \n",
       "2                       Molineux  Chris Kavanagh       [6-5, 5-2, 2-1]   \n",
       "3                  Vicarage Road  Michael Oliver       [4-6, 5-1, 3-1]   \n",
       "4                   Old Trafford    Paul Tierney      [1-3, 12-1, 5-1]   \n",
       "...                          ...             ...                   ...   \n",
       "3063              Craven Cottage      A Marriner       [9-2, 4-7, 5-2]   \n",
       "3064         Turf Moor, Saturday          P Dowd      [2-1, 6-5, 11-5]   \n",
       "3065       St Andrew's, Saturday           C Foy  [23-20, 21-10, 11-5]   \n",
       "3066  Emirates Stadium, Saturday       S Bennett      [1-6, 12-1, 5-1]   \n",
       "3067  Stadium of Light, Saturday         A Wiley      [1-1, 12-5, 9-4]   \n",
       "\n",
       "      odds_home_team  odds_away_team  odds_draw               preview_date  \\\n",
       "0          23.000000        1.166667       9.00  2019-01-19 09:00:12+00:00   \n",
       "1           2.000000        4.333333       3.40  2019-01-18 16:57:35+00:00   \n",
       "2           2.200000        3.500000       3.00  2019-01-18 16:19:44+00:00   \n",
       "3           1.666667        6.000000       4.00  2019-01-18 15:15:04+00:00   \n",
       "4           1.333333       13.000000       6.00  2019-01-18 14:23:22+00:00   \n",
       "...              ...             ...        ...                        ...   \n",
       "3063        5.500000        1.571429       3.50  2009-08-21 21:24:27+00:00   \n",
       "3064        3.000000        2.200000       3.20  2009-08-21 21:21:25+00:00   \n",
       "3065        2.150000        3.100000       3.20  2009-08-21 21:15:59+00:00   \n",
       "3066        1.166667       13.000000       6.00  2009-08-21 21:13:41+00:00   \n",
       "3067        2.000000        3.400000       3.25  2009-08-21 21:08:35+00:00   \n",
       "\n",
       "               game_date                                       preview_link  \n",
       "0    2019-01-20 13:30:00  https://www.theguardian.com/football/2019/jan/...  \n",
       "1    2019-01-19 15:00:00  https://www.theguardian.com/football/2019/jan/...  \n",
       "2    2019-01-19 12:30:00  https://www.theguardian.com/football/2019/jan/...  \n",
       "3    2019-01-19 15:00:00  https://www.theguardian.com/football/2019/jan/...  \n",
       "4    2019-01-19 15:00:00  https://www.theguardian.com/football/2019/jan/...  \n",
       "...                  ...                                                ...  \n",
       "3063 2009-08-23 15:00:00  https://www.theguardian.com/football/2009/aug/...  \n",
       "3064 2009-08-23 14:00:00  https://www.theguardian.com/football/2009/aug/...  \n",
       "3065 2009-08-22 14:00:00  https://www.theguardian.com/football/2009/aug/...  \n",
       "3066 2009-08-22 14:00:00  https://www.theguardian.com/football/2009/aug/...  \n",
       "3067 2009-08-22 14:00:00  https://www.theguardian.com/football/2009/aug/...  \n",
       "\n",
       "[3068 rows x 14 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
