{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp extractor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries and Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "import re\n",
    "import logging\n",
    "from bs4 import BeautifulSoup\n",
    "from typing import Union,List,Dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PageExtractor Class\n",
    "\n",
    "##### This class has five functions for extracting data from a given football preview:\n",
    "\n",
    "1- <b> get_values_matching_regex </b> returns values that match a regex expression.\n",
    "\n",
    "&emsp;The data we want to extract is contained within p tags.<br>\n",
    "&emsp;We go through each p section, and if we find the result, we return it; otherwise, a None is returned.<br>\n",
    "&emsp;The result is a list of tuples, with each tuple representing a value that matches the regex pattern.<br> &emsp;Unsatisfied patterns for regexes that include <b>OR</b> conditions will be empty tuples. That's why we need to get rid of it.\n",
    "\n",
    "2- <b> extract_teams_names </b> returns the names of the two teams in a football preview.\n",
    "\n",
    "&emsp;The preview includes team names at the title level.\n",
    " <br>&emsp;example:\n",
    "          &emsp;&emsp;{{Squad Sheets: Team A v Team B}} \n",
    "         or &emsp;&emsp;{{Team A v Team B: match preview}} \n",
    "         or &emsp;&emsp;{{Team A v Team B: Squad Sheets}}\n",
    "<br>&emsp;As a result, our strategy is to delete the text preceding or following the names and recover each name <br>&emsp;individually.\n",
    "<br>&emsp;If we were successful in obtaining the names, they will be returned in a Python dictionary; <br>&emsp;otherwise, the values will be None (Not available).\n",
    "\n",
    "3- <b> extract_text_authors </b>returns the text and author of a football preview.\n",
    "\n",
    "&emsp;It's difficult to determine the position of the text, but it's almost certainly the block with the most <br>&emsp;characters.\n",
    "<br>&emsp;To proceed, we store each paragraph and its size in a Python dictionary, and then we take the <br>&emsp;block with the largest size.\n",
    "<br>&emsp;To be sure, we double-check by only accepting texts with a size greater than 160 because there <br>&emsp;are football previews with no text or author.\n",
    "<br>&emsp;Furthermore, the author information is always under the text section, more specifically in a <br>&emsp;strong tag, so if the text does not exist, the author is missing as well.\n",
    "If we were successful in <br>&emsp;obtaining the text and the author, they will be returned in a Python dictionary. Otherwise, the <br>&emsp;values will be None (Not available).\n",
    "\n",
    "4- <b> extract_match_infos </b> returns a football match information (venue, referee, odds).\n",
    "\n",
    "&emsp;Here, we'll call the first function <b>get_values_matching_regex</b> , which will allow us to retrieve this<br>&emsp;information by specifying a regex expression for each.<br>&emsp;If this data is not available, the value will be None. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class PageExtractor:\n",
    "    \"\"\"\n",
    "    A class to represent an information extractor from a football preview.\n",
    "\n",
    "    ...\n",
    "\n",
    "    Methods\n",
    "    -------\n",
    "    get_values_matching_regex(content,response_type pattern_returned_values)\n",
    "        return all matched patterns from a preview page.\n",
    "    extract_teams_names(title)\n",
    "        returns team names from the preview title.\n",
    "    extract_text_authors(content, response_type)\n",
    "        returns the text and author of the preview.\n",
    "    extract_match_infos(content, response_type, venue_regex, referee_regex, odds_regex)\n",
    "        returns a football match information (venue,referee,odds).\n",
    "    \"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def get_values_matching_regex(\n",
    "        content: BeautifulSoup, response_type: str, pattern_returned_values: \"re.Pattern\"\n",
    "    ) -> Union[List[str], None]:\n",
    "        \"\"\"\n",
    "        returns all matched patterns from a preview page.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        content: bs4.BeautifulSoup\n",
    "            the html format of the preview content\n",
    "        response_type: str\n",
    "            the parsing method('api' or 'html')\n",
    "        pattern_returned_values: re.Pattern\n",
    "            the regex pattern\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        result: list of str\n",
    "          matched values of the regex expression, None otherwise\n",
    "\n",
    "        \"\"\"\n",
    "        # All Information are located in the \"p tag\" of html\n",
    "        # We pick up all the p tags\n",
    "        if response_type == \"api\":\n",
    "            paragraphs = content.find_all(\"p\")\n",
    "        else:\n",
    "            # some previews in 2009 have a different html tags and classes\n",
    "            all_p_tags_new_formats = content.find_all(\"p\", {\"class\": \"dcr-bixwrd\"})\n",
    "            all_p_tags_old_format = content.select(\"div > p\")\n",
    "            # if exist\n",
    "            if all_p_tags_new_formats:\n",
    "                paragraphs = all_p_tags_new_formats\n",
    "            else:\n",
    "                paragraphs = all_p_tags_old_format\n",
    "\n",
    "        for paragraph in paragraphs:\n",
    "            # We pick up the string values located in the paragraph\n",
    "            # For \"odds\" information, \"Evens\" or \"Evs\" or \"odds-on\" are replaced by 1-1\n",
    "            pattern_odds = re.compile(\"Evens|Evs|odds-on\", re.IGNORECASE)\n",
    "            section = pattern_odds.sub(\"1-1\", paragraph.text)\n",
    "            # To extract our information regex pattern\n",
    "            # To ignore case sensitivity we use re.I\n",
    "            # pattern_returned_values = re.compile(regex, re.IGNORECASE)\n",
    "            # If a regex match is found, we return the list of values.\n",
    "            # otherwise, an empty array is returned.\n",
    "            if pattern_returned_values.findall(section):\n",
    "                matching_result = pattern_returned_values.findall(section)\n",
    "                # remove empty tuples from the list\n",
    "                # example of a matching_result value\n",
    "                # [('12-5', '11-10', '23-10', '', '')]\n",
    "                result = [element for element in matching_result[0] if element]\n",
    "                return result\n",
    "        return None\n",
    "\n",
    "    @staticmethod\n",
    "    def extract_teams_names(title: str) -> Dict[str, object]:\n",
    "        \"\"\"\n",
    "        returns team names from the preview title.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        title: str\n",
    "            the title of the preview\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        names: dict of object\n",
    "\n",
    "        \"\"\"\n",
    "        # 3 possible formats for previews title\n",
    "        # For example:\n",
    "        # {Squad Sheets: Team A v Team B} or\n",
    "        # {{Team A v Team B : match preview}} or\n",
    "        # {{Team A v Team B : Squad sheets}}\n",
    "        # We remove text before or after team names\n",
    "        pattern = re.compile(\n",
    "            \"Squad Sheets:|: Squad[\\s]sheets|Squad sheets|Squad sheet:|: match preview\",\n",
    "            re.IGNORECASE,\n",
    "        )\n",
    "        preview_title = pattern.sub(\"\", title).strip()\n",
    "        # Names are located in the title of the preview\n",
    "        # Home team\n",
    "        try:\n",
    "            home_team = preview_title.split(\" v \")[0]\n",
    "        except Exception as e:\n",
    "            home_team = None\n",
    "            logging.warning(\"Home team name does not exist\")\n",
    "\n",
    "        # Away team\n",
    "        try:\n",
    "            away_team = preview_title.split(\" v \")[1].split(\"\\t\")[\n",
    "                0\n",
    "            ]  # for some preview we find team A v Team B \\t date\n",
    "        except Exception as e:\n",
    "            away_team = None\n",
    "            logging.warning(\"Away team name does not exist\")\n",
    "        # we return names\n",
    "        names = dict({\"home\": home_team, \"away\": away_team})\n",
    "        return names\n",
    "\n",
    "    @staticmethod\n",
    "    def extract_text_authors(\n",
    "        content: BeautifulSoup, response_type: str\n",
    "    ) -> Dict[str, str]:\n",
    "        \"\"\"\n",
    "        returns the text and author of the preview.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        content: bs4.BeautifulSoup\n",
    "            the html format of the preview content\n",
    "        response_type: str\n",
    "            the parsing method('api' or 'html')\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        preview_text_author: dict of str\n",
    "\n",
    "        \"\"\"\n",
    "        # Preview may not have text and author,\n",
    "        # We initialize author and text to None (not available),\n",
    "        author = None\n",
    "        text = None\n",
    "        # all items are stored in a p tag\n",
    "        if response_type == \"api\":\n",
    "            all_p_tags = content.find_all(\"p\")\n",
    "        else:\n",
    "            # Some previews in 2009 have different html tags and classes\n",
    "            all_p_tags_new_formats = content.find_all(\"p\", {\"class\": \"dcr-bixwrd\"})\n",
    "            all_p_tags_old_format = content.select(\"div > p\")\n",
    "            # if exist\n",
    "            if all_p_tags_new_formats:\n",
    "                all_p_tags = all_p_tags_new_formats\n",
    "            else:\n",
    "                all_p_tags = all_p_tags_old_format\n",
    "\n",
    "        # it's quite difficult to determine which section is the text\n",
    "        # the length of the text is usually the longest\n",
    "        # dictionnary to store each p and its length\n",
    "        length_texts = {}\n",
    "        for p in all_p_tags:\n",
    "            section = p.text\n",
    "            length_texts[p] = len(section)\n",
    "\n",
    "        # we pick the section with the largest size\n",
    "        possible_text_section = max(length_texts, key=length_texts.get)\n",
    "        # We double-check and only select texts with a size greater than 160\n",
    "        if len(possible_text_section.text) > 160:\n",
    "            text_section = possible_text_section\n",
    "            text = text_section.text\n",
    "            # the author name is located inside the text section\n",
    "            # it is located in the strong tag\n",
    "            possible_author_section = text_section.find(\"strong\")\n",
    "            # for some previews the author information is not found\n",
    "            # if it's available we take it , else it will be None\n",
    "            if str(possible_author_section) != \"None\":\n",
    "                author = possible_author_section.text\n",
    "        else:\n",
    "            logging.warning(\"There is no text or author information available\")\n",
    "\n",
    "        preview_text_author = dict({\"text\": text, \"author\": author})\n",
    "        return preview_text_author\n",
    "\n",
    "    @staticmethod\n",
    "    def extract_match_infos(\n",
    "        content: BeautifulSoup,\n",
    "        response_type: str,\n",
    "        venue_regex: str,\n",
    "        referee_regex: str,\n",
    "        odds_regex: str,\n",
    "    ) -> Dict[str, object]:\n",
    "        \"\"\"\n",
    "          returns a football match information (venue,referee,odds).\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        content: bs4.BeautifulSoup\n",
    "            the html format of the preview content\n",
    "        response_type: str\n",
    "            the parsing method('api' or 'html')\n",
    "        venue_regex: str\n",
    "            venue regex expression\n",
    "        referee_regex: str\n",
    "            referee regex expression\n",
    "        odds_regex: str\n",
    "            odds regex expression\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        match_infos: dict of object\n",
    "\n",
    "        \"\"\"\n",
    "        # Extract venue, referee and odds values\n",
    "        try:\n",
    "            pattern_venue_values = re.compile(venue_regex)\n",
    "            venue = PageExtractor.get_values_matching_regex(\n",
    "                content, response_type, pattern_venue_values\n",
    "            )[0].strip()\n",
    "        except Exception as e:\n",
    "            logging.error(\"Venue information is not available\")\n",
    "            venue = None\n",
    "        try:\n",
    "            pattern_referee_values = re.compile(referee_regex)\n",
    "            referee = PageExtractor.get_values_matching_regex(\n",
    "                content, response_type, pattern_referee_values\n",
    "            )[0].strip().split(\",\")[0]\n",
    "        except Exception as e:\n",
    "            logging.error(\"Referee information is not available\")\n",
    "            referee = None\n",
    "\n",
    "        pattern_odds_values = re.compile(odds_regex, re.IGNORECASE)\n",
    "        odds = PageExtractor.get_values_matching_regex(\n",
    "            content, response_type, pattern_odds_values\n",
    "        )\n",
    "\n",
    "        match_infos = dict({\"venue\": venue, \"referee\": referee, \"odds\": odds})\n",
    "        return match_infos"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
